{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c05651ec",
   "metadata": {},
   "source": [
    "# DENOISER\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974dee6b",
   "metadata": {},
   "source": [
    "## Dataset creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a844215",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "\n",
    "def get_sidd_image_pairs():\n",
    "    base_dir = 'test/Data'\n",
    "    image_pairs = []\n",
    "        \n",
    "    for subdir in os.listdir(base_dir):\n",
    "        subdir_path = os.path.join(base_dir, subdir)\n",
    "        if os.path.isdir(subdir_path):\n",
    "            gt_images = glob.glob(os.path.join(subdir_path, '*GT_SRGB*.PNG'))\n",
    "            for gt_path in gt_images:\n",
    "                noisy_path = gt_path.replace('GT_SRGB', 'NOISY_SRGB')\n",
    "                if os.path.exists(noisy_path):\n",
    "                    image_pairs.append((gt_path, noisy_path))\n",
    "    \n",
    "    return image_pairs\n",
    "\n",
    "data2_dir = 'data2'\n",
    "if not os.path.exists(data2_dir):\n",
    "    os.makedirs(data2_dir)\n",
    "\n",
    "clean_patches_dir = os.path.join(data2_dir, 'clean')\n",
    "noisy_patches_dir = os.path.join(data2_dir, 'noisy')\n",
    "\n",
    "if not os.path.exists(clean_patches_dir):\n",
    "    os.makedirs(clean_patches_dir)\n",
    "if not os.path.exists(noisy_patches_dir):\n",
    "    os.makedirs(noisy_patches_dir)\n",
    "\n",
    "processed_images_info = {}\n",
    "\n",
    "print('Searching for image pairs...')\n",
    "image_pairs = get_sidd_image_pairs()\n",
    "print(f'Found {len(image_pairs)} image pairs.')\n",
    "\n",
    "#Process each pair of images\n",
    "print('\\nProcessing...')\n",
    "for clean_path, noisy_path in tqdm(image_pairs):\n",
    "    base_name = os.path.splitext(os.path.basename(clean_path))[0]\n",
    "    \n",
    "    #Process the clean image\n",
    "    patches, positions, patch_dims, original_size = create_patches(\n",
    "        clean_path,\n",
    "        output_dir=clean_patches_dir,\n",
    "        prefix=f'{base_name}_clean_')\n",
    "    \n",
    "    #Process the noisy image\n",
    "    create_patches(\n",
    "        noisy_path,\n",
    "        output_dir=noisy_patches_dir,\n",
    "        prefix=f'{base_name}_noisy_')\n",
    "    \n",
    "    processed_images_info[base_name] = {\n",
    "        'patch_positions': positions,\n",
    "        'patch_dimensions': patch_dims,\n",
    "        'original_size': original_size,\n",
    "        'clean_path': clean_path,\n",
    "        'noisy_path': noisy_path}\n",
    "import json\n",
    "with open(os.path.join(data2_dir, 'processing_info.json'), 'w') as f:\n",
    "    json.dump(processed_images_info, f)\n",
    "\n",
    "print('\\nProcessing completed. Patches saved at:', data2_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f822cb",
   "metadata": {},
   "source": [
    "## UNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44d188de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import torchvision.transforms.functional as TF\n",
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from torchmetrics import PeakSignalNoiseRatio, StructuralSimilarityIndexMeasure\n",
    "import gc\n",
    "import json\n",
    "import torchvision.transforms as transforms\n",
    "from scipy.signal import windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2afd7e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 6  \n",
    "EPOCHS = 5\n",
    "LEARNING_RATE = 0.001\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "IMAGE_SIZE = 256\n",
    "CHECKPOINT_DIR = 'checkpoints'\n",
    "\n",
    "#Memory optimization configurations\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "if not os.path.exists(CHECKPOINT_DIR):\n",
    "    os.makedirs(CHECKPOINT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "beaebd93",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenoisingDataset(Dataset):\n",
    "    def __init__(self, clean_dir, noisy_dir, transform=None):\n",
    "        self.clean_dir = clean_dir\n",
    "        self.noisy_dir = noisy_dir\n",
    "        self.transform = transform\n",
    "        \n",
    "        #Obtain all clean patches\n",
    "        self.clean_patches = [f for f in os.listdir(clean_dir) if f.endswith('.png')]\n",
    "        self.clean_patches.sort() \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.clean_patches)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        clean_name = self.clean_patches[idx]\n",
    "        noisy_name = clean_name.replace('clean', 'noisy')\n",
    "        \n",
    "        clean_path = os.path.join(self.clean_dir, clean_name)\n",
    "        noisy_path = os.path.join(self.noisy_dir, noisy_name)\n",
    "        \n",
    "        clean_image = Image.open(clean_path).convert('RGB')\n",
    "        noisy_image = Image.open(noisy_path).convert('RGB')\n",
    "        \n",
    "        if self.transform:\n",
    "            clean_image = self.transform(clean_image)\n",
    "            noisy_image = self.transform(noisy_image)\n",
    "        \n",
    "        return noisy_image, clean_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4a87897",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, in_channels, 3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(in_channels)\n",
    "        self.conv2 = nn.Conv2d(in_channels, in_channels, 3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(in_channels)\n",
    "        self.relu = nn.LeakyReLU(0.2, inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "class SpatialAttention(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, in_channels // 8, 1)\n",
    "        self.conv2 = nn.Conv2d(in_channels // 8, 1, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        att = self.conv1(x)\n",
    "        att = self.conv2(att)\n",
    "        att = self.sigmoid(att)\n",
    "        return x * att\n",
    "\n",
    "#Define the UNet model with skip connections and residual blocks and spatial attention\n",
    "class EnhancedUNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        #Large encoder with residual blocks and spatial attention\n",
    "        self.enc1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            ResidualBlock(64),\n",
    "            SpatialAttention(64)\n",
    "        )\n",
    "        \n",
    "        self.enc2 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, 3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            ResidualBlock(128),\n",
    "            SpatialAttention(128)\n",
    "        )\n",
    "        \n",
    "        self.enc3 = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, 3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            ResidualBlock(256),\n",
    "            SpatialAttention(256)\n",
    "        )\n",
    "        \n",
    "        self.enc4 = nn.Sequential(\n",
    "            nn.Conv2d(256, 512, 3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            ResidualBlock(512),\n",
    "            SpatialAttention(512)\n",
    "        )\n",
    "        \n",
    "        self.bottleneck = nn.Sequential(\n",
    "            nn.Conv2d(512, 1024, 3, padding=1),\n",
    "            nn.BatchNorm2d(1024),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            ResidualBlock(1024),\n",
    "            ResidualBlock(1024),\n",
    "            SpatialAttention(1024)\n",
    "        )\n",
    "        \n",
    "        self.dec4 = nn.Sequential(\n",
    "            nn.Conv2d(1024 + 512, 512, 3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            ResidualBlock(512),\n",
    "            SpatialAttention(512)\n",
    "        )\n",
    "        \n",
    "        self.dec3 = nn.Sequential(\n",
    "            nn.Conv2d(512 + 256, 256, 3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            ResidualBlock(256),\n",
    "            SpatialAttention(256)\n",
    "        )\n",
    "        \n",
    "        self.dec2 = nn.Sequential(\n",
    "            nn.Conv2d(256 + 128, 128, 3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            ResidualBlock(128),\n",
    "            SpatialAttention(128)\n",
    "        )\n",
    "        \n",
    "        self.dec1 = nn.Sequential(\n",
    "            nn.Conv2d(128 + 64, 64, 3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            ResidualBlock(64),\n",
    "            SpatialAttention(64)\n",
    "        )\n",
    "        \n",
    "        self.final = nn.Sequential(\n",
    "            nn.Conv2d(64, 32, 3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(32, 3, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "        self.upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #Encoder path with skip connections\n",
    "        e1 = self.enc1(x)\n",
    "        e2 = self.enc2(self.pool(e1))\n",
    "        e3 = self.enc3(self.pool(e2))\n",
    "        e4 = self.enc4(self.pool(e3))\n",
    "        \n",
    "        #Bottleneck\n",
    "        b = self.bottleneck(self.pool(e4))\n",
    "        \n",
    "        #Decoder path with skip connections\n",
    "        d4 = self.dec4(torch.cat([self.upsample(b), e4], dim=1))\n",
    "        d3 = self.dec3(torch.cat([self.upsample(d4), e3], dim=1))\n",
    "        d2 = self.dec2(torch.cat([self.upsample(d3), e2], dim=1))\n",
    "        d1 = self.dec1(torch.cat([self.upsample(d2), e1], dim=1))\n",
    "        \n",
    "        #Final ootput\n",
    "        out = self.final(d1)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "def6a71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data preparation\n",
    "transform = transforms.Compose([transforms.ToTensor(),])\n",
    "\n",
    "dataset = DenoisingDataset('data2/clean', 'data2/noisy', transform=transform)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, pin_memory=True, num_workers=2)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, pin_memory=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "628349ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dl/miniconda3/envs/dl/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_215065/4020755182.py:10: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler()\n",
      "/home/dl/miniconda3/envs/dl/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.\n",
      "  _future_warning(\n",
      "/home/dl/miniconda3/envs/dl/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `StructuralSimilarityIndexMeasure` from `torchmetrics` was deprecated and will be removed in 2.0. Import `StructuralSimilarityIndexMeasure` from `torchmetrics.image` instead.\n",
      "  _future_warning(\n"
     ]
    }
   ],
   "source": [
    "#Initialize the model, loss function, and optimizer\n",
    "model = EnhancedUNet().to(DEVICE)\n",
    "criterion = nn.L1Loss()  \n",
    "optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=1e-4)  \n",
    "\n",
    "#Learning rate scheduler\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5, verbose=True)\n",
    "\n",
    "#VRAM memory management optimization\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "#Evaluation metrics\n",
    "psnr = PeakSignalNoiseRatio().to(DEVICE)\n",
    "ssim = StructuralSimilarityIndexMeasure().to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38842f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define an optimized training loop\n",
    "def train_epoch(model, train_loader, criterion, optimizer, scaler):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    total_psnr = 0\n",
    "    total_ssim = 0\n",
    "    \n",
    "    for noisy, clean in tqdm(train_loader):\n",
    "        noisy, clean = noisy.to(DEVICE), clean.to(DEVICE)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        with torch.cuda.amp.autocast():\n",
    "            output = model(noisy)\n",
    "            loss = criterion(output, clean)\n",
    "        \n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            total_psnr += psnr(output, clean)\n",
    "            total_ssim += ssim(output, clean)\n",
    "        \n",
    "        #Clear CUDA cache to manage memory\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "    \n",
    "    return total_loss / len(train_loader), total_psnr / len(train_loader), total_ssim / len(train_loader)\n",
    "\n",
    "@torch.no_grad()\n",
    "def validate(model, val_loader, criterion):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    total_psnr = 0\n",
    "    total_ssim = 0\n",
    "    \n",
    "    for noisy, clean in val_loader:\n",
    "        noisy, clean = noisy.to(DEVICE), clean.to(DEVICE)\n",
    "        \n",
    "        with torch.cuda.amp.autocast():\n",
    "            output = model(noisy)\n",
    "            loss = criterion(output, clean)\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        total_psnr += psnr(output, clean)\n",
    "        total_ssim += ssim(output, clean)\n",
    "        \n",
    "        #Clear CUDA cache to manage memory\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "    \n",
    "    return total_loss / len(val_loader), total_psnr / len(val_loader), total_ssim / len(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018e934a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_gaussian_window(patch_size=256):\n",
    "    #Create a 1D Gaussian window\n",
    "    window = windows.gaussian(patch_size, patch_size/6)\n",
    "\n",
    "    #Convert to 2D Gaussian window\n",
    "    window_2d = np.outer(window, window)\n",
    "    window_2d = window_2d / window_2d.max()\n",
    "    \n",
    "    return window_2d\n",
    "\n",
    "def create_patches(image_path, patch_size=256, overlap=26, output_dir=None, prefix=''):\n",
    "    #Load image and convert to RGB\n",
    "    img = Image.open(image_path).convert('RGB')\n",
    "    width, height = img.size\n",
    "    \n",
    "    #Calculate the stride\n",
    "    stride = patch_size - overlap\n",
    "    \n",
    "    #Calculate the number of patches\n",
    "    n_patches_w = (width - overlap) // stride\n",
    "    n_patches_h = (height - overlap) // stride\n",
    "    \n",
    "    patches = []\n",
    "    patch_positions = []\n",
    "    \n",
    "    window = create_gaussian_window(patch_size)\n",
    "    \n",
    "    #Extract patches\n",
    "    for i in range(n_patches_h):\n",
    "        for j in range(n_patches_w):\n",
    "            left = j * stride\n",
    "            top = i * stride\n",
    "            right = left + patch_size\n",
    "            bottom = top + patch_size\n",
    "            \n",
    "            if right > width or bottom > height:\n",
    "                continue\n",
    "            \n",
    "            patch = img.crop((left, top, right, bottom))\n",
    "            \n",
    "            if output_dir:\n",
    "                #Save patches\n",
    "                patch_name = f'{prefix}patch_{i}_{j}.png'\n",
    "                patch_path = os.path.join(output_dir, patch_name)\n",
    "                patch.save(patch_path)\n",
    "            \n",
    "            patches.append(patch)\n",
    "            patch_positions.append((left, top))\n",
    "    \n",
    "    return patches, patch_positions, (n_patches_h, n_patches_w), (width, height), window\n",
    "\n",
    "def reconstruct_image(patches, patch_positions, original_size, window, patch_size=256):\n",
    "    width, height = original_size\n",
    "    \n",
    "    #Create a blank image for reconstruction\n",
    "    reconstructed = np.zeros((height, width, 3))\n",
    "    weights = np.zeros((height, width))\n",
    "    \n",
    "    #Process each patch\n",
    "    for patch, (left, top) in zip(patches, patch_positions):\n",
    "        patch_array = np.array(patch)\n",
    "        \n",
    "        #Apply the Gaussian window\n",
    "        for c in range(3):  \n",
    "            reconstructed[top:top+patch_size, left:left+patch_size, c] += \\\n",
    "                patch_array[:, :, c] * window\n",
    "        \n",
    "        #Accumulate weights\n",
    "        weights[top:top+patch_size, left:left+patch_size] += window\n",
    "    \n",
    "    weights = np.maximum(weights, 1e-10)\n",
    "    for c in range(3):\n",
    "        reconstructed[:, :, c] /= weights\n",
    "    \n",
    "    #Create the final image\n",
    "    reconstructed = np.clip(reconstructed, 0, 255).astype(np.uint8)\n",
    "    reconstructed = Image.fromarray(reconstructed)\n",
    "    \n",
    "    return reconstructed\n",
    "\n",
    "def evaluate_full_images(model, device, processing_info_path='data2/processing_info.json'):\n",
    "    model.eval()\n",
    "    \n",
    "    if not os.path.exists('final_results'):\n",
    "        os.makedirs('final_results')\n",
    "    \n",
    "    with open(processing_info_path, 'r') as f:\n",
    "        processing_info = json.load(f)\n",
    "    \n",
    "    results = []\n",
    "    transform = transforms.ToTensor()\n",
    "    \n",
    "    for img_name, info in processing_info.items():\n",
    "        print(f'Processing image:  {img_name}...')\n",
    "        original_size = tuple(info['original_size'])\n",
    "        \n",
    "        base_path = info['noisy_path']\n",
    "        clean_path = info['clean_path']\n",
    "        \n",
    "        patches_noisy, positions, _, _, window = create_patches(base_path, output_dir=None)\n",
    "        patches_clean, _, _, _, _ = create_patches(clean_path, output_dir=None)\n",
    "        \n",
    "        #Process each patch\n",
    "        denoised_patches = []\n",
    "        with torch.no_grad():\n",
    "            for patch in patches_noisy:\n",
    "                patch_tensor = transform(patch).unsqueeze(0).to(device)\n",
    "                denoised_patch = model(patch_tensor)\n",
    "                denoised_patch = transforms.ToPILImage()(denoised_patch.squeeze().cpu())\n",
    "                denoised_patches.append(denoised_patch)\n",
    "        \n",
    "        #Reconstruct the full images\n",
    "        noisy_full = reconstruct_image(patches_noisy, positions, original_size, window)\n",
    "        clean_full = reconstruct_image(patches_clean, positions, original_size, window)\n",
    "        denoised_full = reconstruct_image(denoised_patches, positions, original_size, window)\n",
    "        \n",
    "        #Save the images\n",
    "        base_name = os.path.splitext(os.path.basename(base_path))[0]\n",
    "        noisy_save_path = os.path.join('final_results', f'{base_name}_noisy.png')\n",
    "        clean_save_path = os.path.join('final_results', f'{base_name}_clean.png')\n",
    "        denoised_save_path = os.path.join('final_results', f'{base_name}_denoised.png')\n",
    "        \n",
    "        noisy_full.save(noisy_save_path)\n",
    "        clean_full.save(clean_save_path)\n",
    "        denoised_full.save(denoised_save_path)\n",
    "        \n",
    "        #Calculate PSNR and SSIM\n",
    "        noisy_tensor = transform(noisy_full).unsqueeze(0).to(device)\n",
    "        clean_tensor = transform(clean_full).unsqueeze(0).to(device)\n",
    "        denoised_tensor = transform(denoised_full).unsqueeze(0).to(device)\n",
    "        \n",
    "        psnr_val = psnr(denoised_tensor, clean_tensor)\n",
    "        ssim_val = ssim(denoised_tensor, clean_tensor)\n",
    "        \n",
    "        results.append({\n",
    "            'image_name': base_name,\n",
    "            'psnr': psnr_val.item(),\n",
    "            'ssim': ssim_val.item(),\n",
    "            'paths': {\n",
    "                'noisy': noisy_save_path,\n",
    "                'clean': clean_save_path,\n",
    "                'denoised': denoised_save_path\n",
    "            }\n",
    "        })\n",
    "        \n",
    "        print(f'PSNR: {psnr_val:.2f}, SSIM: {ssim_val:.4f}')\n",
    "    \n",
    "    with open('final_results/metrics.json', 'w') as f:\n",
    "        json.dump(results, f, indent=4)\n",
    "    \n",
    "    return results\n",
    "\n",
    "#Training loop\n",
    "best_val_loss = float('inf')\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "train_psnrs = []\n",
    "val_psnrs = []\n",
    "train_ssims = []\n",
    "val_ssims = []\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    train_loss, train_psnr_val, train_ssim_val = train_epoch(model, train_loader, criterion, optimizer, scaler)\n",
    "    val_loss, val_psnr_val, val_ssim_val = validate(model, val_loader, criterion)\n",
    "    \n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    train_psnrs.append(train_psnr_val)\n",
    "    val_psnrs.append(val_psnr_val)\n",
    "    train_ssims.append(train_ssim_val)\n",
    "    val_ssims.append(val_ssim_val)\n",
    "    \n",
    "    print(f'Epoch {epoch+1}/{EPOCHS}:')\n",
    "    print(f'Train Loss: {train_loss:.6f}, Train PSNR: {train_psnr_val:.2f}, Train SSIM: {train_ssim_val:.4f}')\n",
    "    print(f'Val Loss: {val_loss:.6f}, Val PSNR: {val_psnr_val:.2f}, Val SSIM: {val_ssim_val:.4f}')\n",
    "    \n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'val_loss': val_loss,\n",
    "        }, f'{CHECKPOINT_DIR}/best_model.pth')\n",
    "    \n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'val_loss': val_loss,\n",
    "    }, f'{CHECKPOINT_DIR}/checkpoint_epoch_{epoch+1}.pth')\n",
    "                \n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "#Create a function to plot training progress\n",
    "def plot_training_progress(train_losses, val_losses, train_psnrs, val_psnrs, train_ssims, val_ssims):\n",
    "    epochs = range(1, len(train_losses) + 1)\n",
    "    \n",
    "    plt.figure(figsize=(18, 12))\n",
    "    \n",
    "    #Loss plot\n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.plot(epochs, train_losses, 'b-', label='Training loss')\n",
    "    plt.plot(epochs, val_losses, 'r-', label='Validation loss')\n",
    "    plt.title('TRAINING AND VALIDATION LOSS')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    #PSNR plot\n",
    "    plt.subplot(2, 2, 2)\n",
    "    plt.plot(epochs, train_psnrs, 'b-', label='Training PSNR')\n",
    "    plt.plot(epochs, val_psnrs, 'r-', label='Validation PSNR')\n",
    "    plt.title('TRAINING AND VALIDATION PSNR')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('PSNR (dB)')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    #SSIM plot\n",
    "    plt.subplot(2, 2, 3)\n",
    "    plt.plot(epochs, train_ssims, 'b-', label='Training SSIM')\n",
    "    plt.plot(epochs, val_ssims, 'r-', label='Validation SSIM')\n",
    "    plt.title('TRAINING AND VALIDATION SSIM')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('SSIM')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    #Combined plot\n",
    "    plt.subplot(2, 2, 4)\n",
    "    \n",
    "    #Normalize the metrics for better visualization\n",
    "    def normalize(data):\n",
    "        return (data - np.min(data)) / (np.max(data) - np.min(data) + 1e-8)\n",
    "    \n",
    "    norm_train_loss = normalize(train_losses)\n",
    "    norm_val_loss = normalize(val_losses)\n",
    "    norm_train_psnr = normalize(train_psnrs)\n",
    "    norm_val_psnr = normalize(val_psnrs)\n",
    "    norm_train_ssim = normalize(train_ssims)\n",
    "    norm_val_ssim = normalize(val_ssims)\n",
    "    \n",
    "    plt.plot(epochs, norm_train_loss, 'b--', label='Norm train loss')\n",
    "    plt.plot(epochs, norm_val_loss, 'r--', label='Norm val loss')\n",
    "    plt.plot(epochs, norm_train_psnr, 'g-', label='Norm train PSNR')\n",
    "    plt.plot(epochs, norm_val_psnr, 'm-', label='Norm val PSNR')\n",
    "    plt.plot(epochs, norm_train_ssim, 'c-', label='Norm train SSIM')\n",
    "    plt.plot(epochs, norm_val_ssim, 'y-', label='Norm val SSIM')\n",
    "    \n",
    "    plt.title('NORMALIZED TRAINING AND VALIDATION METRICS')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Normalized value')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{CHECKPOINT_DIR}/training_progress.png')\n",
    "    plt.show()\n",
    "\n",
    "#Visualize training progress\n",
    "plot_training_progress(train_losses, val_losses, train_psnrs, val_psnrs, train_ssims, val_ssims)\n",
    "\n",
    "print('\\nTraining completed. Evaluating the final model with full images...')\n",
    "final_results = evaluate_full_images(model, DEVICE)\n",
    "\n",
    "def show_final_results(results, num_samples=4):\n",
    "    num_samples = min(num_samples, len(results))\n",
    "    fig, axes = plt.subplots(num_samples, 3, figsize=(15, 5*num_samples))\n",
    "    \n",
    "    for i, result in enumerate(results[:num_samples]):\n",
    "        noisy = Image.open(result['paths']['noisy'])\n",
    "        clean = Image.open(result['paths']['clean'])\n",
    "        denoised = Image.open(result['paths']['denoised'])\n",
    "        \n",
    "        axes[i, 0].imshow(noisy)\n",
    "        axes[i, 0].set_title('Noisy')\n",
    "        axes[i, 0].axis('off')\n",
    "        \n",
    "        axes[i, 1].imshow(denoised)\n",
    "        axes[i, 1].set_title(f'Denoised\\nPSNR: {result[\"psnr\"]:.2f}, SSIM: {result[\"ssim\"]:.4f}')\n",
    "        axes[i, 1].axis('off')\n",
    "        \n",
    "        axes[i, 2].imshow(clean)\n",
    "        axes[i, 2].set_title('Clean')\n",
    "        axes[i, 2].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "show_final_results(final_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667ab700",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and evaluate the best model\n",
    "import os\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import json\n",
    "from torchvision import transforms\n",
    "\n",
    "# Load the best model from checkpoint\n",
    "BEST_MODEL_PATH = os.path.join(CHECKPOINT_DIR, 'best_model.pth')\n",
    "\n",
    "if os.path.exists(BEST_MODEL_PATH):\n",
    "    print(f'Loading best model from {BEST_MODEL_PATH}')\n",
    "    \n",
    "    # Create a model instance\n",
    "    best_model = EnhancedUNet().to(DEVICE)\n",
    "    \n",
    "    # Load the model weights\n",
    "    checkpoint = torch.load(BEST_MODEL_PATH, map_location=DEVICE)\n",
    "    best_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    best_epoch = checkpoint['epoch']\n",
    "    best_val_loss = checkpoint['val_loss']\n",
    "    \n",
    "    print(f'Best model from epoch {best_epoch+1} with validation loss {best_val_loss:.6f}')\n",
    "    \n",
    "    # Set the model to evaluation mode\n",
    "    best_model.eval()\n",
    "    \n",
    "    # Create directory for best model results\n",
    "    BEST_RESULTS_DIR = 'best_model_results'\n",
    "    if not os.path.exists(BEST_RESULTS_DIR):\n",
    "        os.makedirs(BEST_RESULTS_DIR)\n",
    "    \n",
    "    # Evaluate the best model on full images\n",
    "    print('\\nEvaluating the best model with full images...')\n",
    "    best_results = evaluate_full_images(best_model, DEVICE)\n",
    "    \n",
    "    # Save results in best_model_results directory\n",
    "    for result in best_results:\n",
    "        base_name = os.path.basename(result['paths']['denoised'])\n",
    "        new_path = os.path.join(BEST_RESULTS_DIR, base_name)\n",
    "        img = Image.open(result['paths']['denoised'])\n",
    "        img.save(new_path)\n",
    "        \n",
    "        # Update the path in the result\n",
    "        result['paths']['best_denoised'] = new_path\n",
    "    \n",
    "    # Save metrics to JSON\n",
    "    with open(os.path.join(BEST_RESULTS_DIR, 'best_model_metrics.json'), 'w') as f:\n",
    "        json.dump(best_results, f, indent=4)\n",
    "    \n",
    "    # Show the results\n",
    "    print('\\nShowing best model results:')\n",
    "    show_final_results(best_results)\n",
    "    \n",
    "    # Compare best model with final model\n",
    "    def compare_models_results(final_results, best_results, num_samples=2):\n",
    "        num_samples = min(num_samples, len(final_results), len(best_results))\n",
    "        fig, axes = plt.subplots(num_samples, 4, figsize=(20, 5*num_samples))\n",
    "        \n",
    "        for i in range(num_samples):\n",
    "            # Get corresponding results (assuming they're in the same order)\n",
    "            final_result = final_results[i]\n",
    "            best_result = best_results[i]\n",
    "            \n",
    "            # Load images\n",
    "            noisy = Image.open(final_result['paths']['noisy'])\n",
    "            clean = Image.open(final_result['paths']['clean'])\n",
    "            final_denoised = Image.open(final_result['paths']['denoised'])\n",
    "            best_denoised = Image.open(best_result['paths']['denoised'])\n",
    "            \n",
    "            # Display images\n",
    "            axes[i, 0].imshow(noisy)\n",
    "            axes[i, 0].set_title('Noisy')\n",
    "            axes[i, 0].axis('off')\n",
    "            \n",
    "            axes[i, 1].imshow(best_denoised)\n",
    "            axes[i, 1].set_title(f'Best Model\\nPSNR: {best_result[\"psnr\"]:.2f}, SSIM: {best_result[\"ssim\"]:.4f}')\n",
    "            axes[i, 1].axis('off')\n",
    "            \n",
    "            axes[i, 2].imshow(final_denoised)\n",
    "            axes[i, 2].set_title(f'Final Model\\nPSNR: {final_result[\"psnr\"]:.2f}, SSIM: {final_result[\"ssim\"]:.4f}')\n",
    "            axes[i, 2].axis('off')\n",
    "            \n",
    "            axes[i, 3].imshow(clean)\n",
    "            axes[i, 3].set_title('Clean')\n",
    "            axes[i, 3].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(BEST_RESULTS_DIR, 'model_comparison.png'))\n",
    "        plt.show()\n",
    "    \n",
    "    print('\\nComparing best model with final model:')\n",
    "    compare_models_results(final_results, best_results)\n",
    "    \n",
    "    # Calculate and print average metrics\n",
    "    final_avg_psnr = sum(r['psnr'] for r in final_results) / len(final_results)\n",
    "    final_avg_ssim = sum(r['ssim'] for r in final_results) / len(final_results)\n",
    "    best_avg_psnr = sum(r['psnr'] for r in best_results) / len(best_results)\n",
    "    best_avg_ssim = sum(r['ssim'] for r in best_results) / len(best_results)\n",
    "    \n",
    "    print('\\nAverage Metrics:')\n",
    "    print(f'Final Model - PSNR: {final_avg_psnr:.2f}, SSIM: {final_avg_ssim:.4f}')\n",
    "    print(f'Best Model - PSNR: {best_avg_psnr:.2f}, SSIM: {best_avg_ssim:.4f}')\n",
    "    \n",
    "    # Evaluate on external test images from Test_images folder\n",
    "    def test_external_images(model, device, test_dir='Test_images', output_dir='external_test_results'):\n",
    "        if not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir)\n",
    "        \n",
    "        test_files = [f for f in os.listdir(test_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "        transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "        ])\n",
    "        \n",
    "        results = []\n",
    "        \n",
    "        for img_file in test_files:\n",
    "            img_path = os.path.join(test_dir, img_file)\n",
    "            print(f'Processing {img_file}...')\n",
    "            \n",
    "            # Load and process the image\n",
    "            img = Image.open(img_path).convert('RGB')\n",
    "            \n",
    "            # Create patches for large images\n",
    "            patches, positions, _, original_size, window = create_patches(img_path, output_dir=None)\n",
    "            \n",
    "            # Process each patch\n",
    "            denoised_patches = []\n",
    "            with torch.no_grad():\n",
    "                for patch in patches:\n",
    "                    patch_tensor = transform(patch).unsqueeze(0).to(device)\n",
    "                    denoised_patch = model(patch_tensor)\n",
    "                    denoised_patch = transforms.ToPILImage()(denoised_patch.squeeze().cpu())\n",
    "                    denoised_patches.append(denoised_patch)\n",
    "            \n",
    "            # Reconstruct the full image\n",
    "            noisy_full = img\n",
    "            denoised_full = reconstruct_image(denoised_patches, positions, original_size, window)\n",
    "            \n",
    "            # Save the images\n",
    "            base_name = os.path.splitext(img_file)[0]\n",
    "            denoised_save_path = os.path.join(output_dir, f'{base_name}_denoised.png')\n",
    "            \n",
    "            denoised_full.save(denoised_save_path)\n",
    "            \n",
    "            results.append({\n",
    "                'image_name': base_name,\n",
    "                'original_path': img_path,\n",
    "                'denoised_path': denoised_save_path\n",
    "            })\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    # Check if Test_images directory exists and has images\n",
    "    if os.path.exists('Test_images') and any(f.lower().endswith(('.png', '.jpg', '.jpeg')) for f in os.listdir('Test_images')):\n",
    "        print('\\nTesting on external images...')\n",
    "        external_results = test_external_images(best_model, DEVICE)\n",
    "        \n",
    "        # Display external test results\n",
    "        def show_external_results(results, num_samples=4):\n",
    "            num_samples = min(num_samples, len(results))\n",
    "            fig, axes = plt.subplots(num_samples, 2, figsize=(10, 5*num_samples))\n",
    "            \n",
    "            # Handle case with single sample\n",
    "            if num_samples == 1:\n",
    "                axes = [axes]\n",
    "            \n",
    "            for i, result in enumerate(results[:num_samples]):\n",
    "                noisy = Image.open(result['original_path'])\n",
    "                denoised = Image.open(result['denoised_path'])\n",
    "                \n",
    "                axes[i, 0].imshow(noisy)\n",
    "                axes[i, 0].set_title('Original')\n",
    "                axes[i, 0].axis('off')\n",
    "                \n",
    "                axes[i, 1].imshow(denoised)\n",
    "                axes[i, 1].set_title('Denoised')\n",
    "                axes[i, 1].axis('off')\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.savefig('external_test_results/external_results.png')\n",
    "            plt.show()\n",
    "        \n",
    "        if external_results:\n",
    "            show_external_results(external_results)\n",
    "    \n",
    "else:\n",
    "    print(f'Error: Best model not found at {BEST_MODEL_PATH}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
