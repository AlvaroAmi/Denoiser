{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c05651ec",
   "metadata": {},
   "source": [
    "# DENOISER\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974dee6b",
   "metadata": {},
   "source": [
    "## Dataset creation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1cac582",
   "metadata": {},
   "source": [
    "Dataset: https://www.kaggle.com/datasets/hsankesara/flickr-image-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367c2928",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "#Define the paths to the directories\n",
    "raw_data_dir = 'rawdata'\n",
    "output_dir = 'Data'\n",
    "clean_dir = os.path.join(output_dir, 'clean')\n",
    "noisy_dir = os.path.join(output_dir, 'noisy')\n",
    "\n",
    "os.makedirs(clean_dir, exist_ok=True)\n",
    "os.makedirs(noisy_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d66281f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_gaussian_noise(image, mean=0, sigma=25):\n",
    "    row, col, ch = image.shape\n",
    "    gauss = np.random.normal(mean, sigma, (row, col, ch))\n",
    "    noisy = image + gauss\n",
    "    noisy = np.clip(noisy, 0, 255)\n",
    "    return noisy.astype(np.uint8)\n",
    "\n",
    "def add_salt_and_pepper_noise(image, prob=0.05):\n",
    "    output = np.copy(image)\n",
    "    #Salt mode\n",
    "    salt_mask = np.random.random(image.shape) < prob/2\n",
    "    output[salt_mask] = 255\n",
    "    #Pepper mode\n",
    "    pepper_mask = np.random.random(image.shape) < prob/2\n",
    "    output[pepper_mask] = 0\n",
    "    return output\n",
    "\n",
    "def add_poisson_noise(image, scale=1.0):\n",
    "    noisy = np.random.poisson(image * scale) / scale\n",
    "    return np.clip(noisy, 0, 255).astype(np.uint8)\n",
    "\n",
    "def add_speckle_noise(image, std=0.1):\n",
    "    noise = np.random.normal(0, std, image.shape)\n",
    "    noisy = image + image * noise\n",
    "    return np.clip(noisy, 0, 255).astype(np.uint8)\n",
    "\n",
    "#List of noise functions and their parameters\n",
    "noise_functions = [\n",
    "    (add_gaussian_noise, {}),\n",
    "    (add_salt_and_pepper_noise, {}),\n",
    "    (add_poisson_noise, {'scale': 1.0}),\n",
    "    (add_speckle_noise, {})\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38995398",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Process images\n",
    "image_files = os.listdir(raw_data_dir)\n",
    "target_size = (256, 256)\n",
    "\n",
    "for idx, img_name in enumerate(tqdm(image_files)):\n",
    "    if not img_name.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "        continue\n",
    "        \n",
    "    #Read image\n",
    "    img_path = os.path.join(raw_data_dir, img_name)\n",
    "    img = cv2.imread(img_path)\n",
    "    if img is None:\n",
    "        continue\n",
    "        \n",
    "    #Resize image\n",
    "    img_resized = cv2.resize(img, target_size)\n",
    "    \n",
    "    #Save clean image\n",
    "    clean_path = os.path.join(clean_dir, f'{idx:05d}.png')\n",
    "    cv2.imwrite(clean_path, img_resized)\n",
    "    \n",
    "    #Select random noise function\n",
    "    noise_func, params = random.choice(noise_functions)\n",
    "    \n",
    "    #Add noise to image\n",
    "    noisy_img = noise_func(img_resized, **params)\n",
    "    \n",
    "    #Save noisy image\n",
    "    noisy_path = os.path.join(noisy_dir, f'{idx:05d}.png')\n",
    "    cv2.imwrite(noisy_path, noisy_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442e6373",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check the number of images generated\n",
    "print(f\"Clean images generated: {len(os.listdir(clean_dir))}\")\n",
    "print(f\"Noisy images generated: {len(os.listdir(noisy_dir))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f822cb",
   "metadata": {},
   "source": [
    "## UNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d188de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import torchvision.transforms.functional as TF\n",
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from torchmetrics import PeakSignalNoiseRatio, StructuralSimilarityIndexMeasure\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2afd7e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 6  \n",
    "EPOCHS = 100\n",
    "LEARNING_RATE = 0.001\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "IMAGE_SIZE = 256\n",
    "CHECKPOINT_DIR = 'checkpoints'\n",
    "\n",
    "#Memory optimization configurations\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "if not os.path.exists(CHECKPOINT_DIR):\n",
    "    os.makedirs(CHECKPOINT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beaebd93",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenoisingDataset(Dataset):\n",
    "    def __init__(self, clean_dir, noisy_dir, transform=None):\n",
    "        self.clean_dir = clean_dir\n",
    "        self.noisy_dir = noisy_dir\n",
    "        self.transform = transform\n",
    "        self.image_files = os.listdir(clean_dir)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.image_files[idx]\n",
    "        clean_image = Image.open(os.path.join(self.clean_dir, img_name))\n",
    "        noisy_image = Image.open(os.path.join(self.noisy_dir, img_name))\n",
    "        \n",
    "        if self.transform:\n",
    "            clean_image = self.transform(clean_image)\n",
    "            noisy_image = self.transform(noisy_image)\n",
    "        \n",
    "        return noisy_image, clean_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a87897",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, in_channels, 3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(in_channels)\n",
    "        self.conv2 = nn.Conv2d(in_channels, in_channels, 3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(in_channels)\n",
    "        self.relu = nn.LeakyReLU(0.2, inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "class SpatialAttention(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, in_channels // 8, 1)\n",
    "        self.conv2 = nn.Conv2d(in_channels // 8, 1, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        att = self.conv1(x)\n",
    "        att = self.conv2(att)\n",
    "        att = self.sigmoid(att)\n",
    "        return x * att\n",
    "\n",
    "#Define the UNet model with better skip connections and residual blocks and spatial attention\n",
    "class EnhancedUNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        #Large encoder with residual blocks and spatial attention\n",
    "        self.enc1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            ResidualBlock(64),\n",
    "            SpatialAttention(64)\n",
    "        )\n",
    "        \n",
    "        self.enc2 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, 3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            ResidualBlock(128),\n",
    "            SpatialAttention(128)\n",
    "        )\n",
    "        \n",
    "        self.enc3 = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, 3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            ResidualBlock(256),\n",
    "            SpatialAttention(256)\n",
    "        )\n",
    "        \n",
    "        self.enc4 = nn.Sequential(\n",
    "            nn.Conv2d(256, 512, 3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            ResidualBlock(512),\n",
    "            SpatialAttention(512)\n",
    "        )\n",
    "        \n",
    "        self.bottleneck = nn.Sequential(\n",
    "            nn.Conv2d(512, 1024, 3, padding=1),\n",
    "            nn.BatchNorm2d(1024),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            ResidualBlock(1024),\n",
    "            ResidualBlock(1024),\n",
    "            SpatialAttention(1024)\n",
    "        )\n",
    "        \n",
    "        self.dec4 = nn.Sequential(\n",
    "            nn.Conv2d(1024 + 512, 512, 3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            ResidualBlock(512),\n",
    "            SpatialAttention(512)\n",
    "        )\n",
    "        \n",
    "        self.dec3 = nn.Sequential(\n",
    "            nn.Conv2d(512 + 256, 256, 3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            ResidualBlock(256),\n",
    "            SpatialAttention(256)\n",
    "        )\n",
    "        \n",
    "        self.dec2 = nn.Sequential(\n",
    "            nn.Conv2d(256 + 128, 128, 3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            ResidualBlock(128),\n",
    "            SpatialAttention(128)\n",
    "        )\n",
    "        \n",
    "        self.dec1 = nn.Sequential(\n",
    "            nn.Conv2d(128 + 64, 64, 3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            ResidualBlock(64),\n",
    "            SpatialAttention(64)\n",
    "        )\n",
    "        \n",
    "        self.final = nn.Sequential(\n",
    "            nn.Conv2d(64, 32, 3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(32, 3, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "        self.upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #Encoder path with skip connections\n",
    "        e1 = self.enc1(x)\n",
    "        e2 = self.enc2(self.pool(e1))\n",
    "        e3 = self.enc3(self.pool(e2))\n",
    "        e4 = self.enc4(self.pool(e3))\n",
    "        \n",
    "        # Bottleneck\n",
    "        b = self.bottleneck(self.pool(e4))\n",
    "        \n",
    "        # Decoder path with skip connections\n",
    "        d4 = self.dec4(torch.cat([self.upsample(b), e4], dim=1))\n",
    "        d3 = self.dec3(torch.cat([self.upsample(d4), e3], dim=1))\n",
    "        d2 = self.dec2(torch.cat([self.upsample(d3), e2], dim=1))\n",
    "        d1 = self.dec1(torch.cat([self.upsample(d2), e1], dim=1))\n",
    "        \n",
    "        #Final ootput\n",
    "        out = self.final(d1)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def6a71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data preparation\n",
    "transform = transforms.Compose([transforms.ToTensor(),])\n",
    "\n",
    "dataset = DenoisingDataset('Data/clean', 'Data/noisy', transform=transform)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, pin_memory=True, num_workers=2)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, pin_memory=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628349ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize the model, loss function, and optimizer\n",
    "model = EnhancedUNet().to(DEVICE)\n",
    "criterion = nn.L1Loss()  \n",
    "optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=1e-4)  \n",
    "\n",
    "#Learning rate scheduler\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5, verbose=True)\n",
    "\n",
    "#VRAM memory management optimization\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "#Evaluation metrics\n",
    "psnr = PeakSignalNoiseRatio().to(DEVICE)\n",
    "ssim = StructuralSimilarityIndexMeasure().to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38842f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define an optimized training loop\n",
    "def train_epoch(model, train_loader, criterion, optimizer, scaler):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    total_psnr = 0\n",
    "    total_ssim = 0\n",
    "    \n",
    "    for noisy, clean in tqdm(train_loader):\n",
    "        noisy, clean = noisy.to(DEVICE), clean.to(DEVICE)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        with torch.cuda.amp.autocast():\n",
    "            output = model(noisy)\n",
    "            loss = criterion(output, clean)\n",
    "        \n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            total_psnr += psnr(output, clean)\n",
    "            total_ssim += ssim(output, clean)\n",
    "        \n",
    "        #Clear CUDA cache to manage memory\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "    \n",
    "    return total_loss / len(train_loader), total_psnr / len(train_loader), total_ssim / len(train_loader)\n",
    "\n",
    "@torch.no_grad()\n",
    "def validate(model, val_loader, criterion):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    total_psnr = 0\n",
    "    total_ssim = 0\n",
    "    \n",
    "    for noisy, clean in val_loader:\n",
    "        noisy, clean = noisy.to(DEVICE), clean.to(DEVICE)\n",
    "        \n",
    "        with torch.cuda.amp.autocast():\n",
    "            output = model(noisy)\n",
    "            loss = criterion(output, clean)\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        total_psnr += psnr(output, clean)\n",
    "        total_ssim += ssim(output, clean)\n",
    "        \n",
    "        #Clear CUDA cache to manage memory\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "    \n",
    "    return total_loss / len(val_loader), total_psnr / len(val_loader), total_ssim / len(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018e934a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training loop\n",
    "best_val_loss = float('inf')\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "train_psnrs = []\n",
    "val_psnrs = []\n",
    "train_ssims = []\n",
    "val_ssims = []\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    train_loss, train_psnr_val, train_ssim_val = train_epoch(model, train_loader, criterion, optimizer, scaler)\n",
    "    val_loss, val_psnr_val, val_ssim_val = validate(model, val_loader, criterion)\n",
    "    \n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    train_psnrs.append(train_psnr_val)\n",
    "    val_psnrs.append(val_psnr_val)\n",
    "    train_ssims.append(train_ssim_val)\n",
    "    val_ssims.append(val_ssim_val)\n",
    "    \n",
    "    print(f'Epoch {epoch+1}/{EPOCHS}:')\n",
    "    print(f'Train Loss: {train_loss:.6f}, Train PSNR: {train_psnr_val:.2f}, Train SSIM: {train_ssim_val:.4f}')\n",
    "    print(f'Val Loss: {val_loss:.6f}, Val PSNR: {val_psnr_val:.2f}, Val SSIM: {val_ssim_val:.4f}')\n",
    "    \n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'val_loss': val_loss,\n",
    "        }, f'{CHECKPOINT_DIR}/best_model.pth')\n",
    "    \n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'val_loss': val_loss,\n",
    "        }, f'{CHECKPOINT_DIR}/checkpoint_epoch_{epoch+1}.pth')\n",
    "        \n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56f364c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Metrics visualization\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(train_losses, label='Train Loss')\n",
    "plt.plot(val_losses, label='Val Loss')\n",
    "plt.title('Loss Evolution')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(train_psnrs, label='Train PSNR')\n",
    "plt.plot(val_psnrs, label='Val PSNR')\n",
    "plt.title('PSNR Evolution')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(train_ssims, label='Train SSIM')\n",
    "plt.plot(val_ssims, label='Val SSIM')\n",
    "plt.title('SSIM Evolution')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550c6112",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the best model\n",
    "def load_best_model():\n",
    "    best_model = EnhancedUNet().to(DEVICE)\n",
    "    checkpoint = torch.load(f'{CHECKPOINT_DIR}/best_model.pth')\n",
    "    best_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    print(f\"Loading the best model from epoch:  {checkpoint['epoch']} with validation loss:  {checkpoint['val_loss']:.6f}\")\n",
    "    return best_model\n",
    "\n",
    "best_model = load_best_model()\n",
    "best_model.eval()\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "with torch.no_grad():\n",
    "    #Take some test images from the validation set\n",
    "    test_noisy, test_clean = next(iter(val_loader))\n",
    "    test_noisy, test_clean = test_noisy.to(DEVICE), test_clean.to(DEVICE)\n",
    "    test_output = best_model(test_noisy)\n",
    "    \n",
    "    #Show the results\n",
    "    fig, axes = plt.subplots(4, 3, figsize=(15, 20))\n",
    "    for i in range(4):\n",
    "        #Noisy image\n",
    "        noisy_img = test_noisy[i].cpu().permute(1, 2, 0).numpy()\n",
    "        axes[i, 0].imshow(np.clip(noisy_img, 0, 1))\n",
    "        axes[i, 0].set_title('Noisy')\n",
    "        axes[i, 0].axis('off')\n",
    "        \n",
    "        #Model output\n",
    "        denoised_img = test_output[i].cpu().permute(1, 2, 0).numpy()\n",
    "        axes[i, 1].imshow(np.clip(denoised_img, 0, 1))\n",
    "        axes[i, 1].set_title('Denoised (Best model)')\n",
    "        axes[i, 1].axis('off')\n",
    "        \n",
    "        #Original clean image\n",
    "        clean_img = test_clean[i].cpu().permute(1, 2, 0).numpy()\n",
    "        axes[i, 2].imshow(np.clip(clean_img, 0, 1))\n",
    "        axes[i, 2].set_title('Clean')\n",
    "        axes[i, 2].axis('off')\n",
    "        \n",
    "        #Calculate PSNR and SSIM for each image\n",
    "        img_psnr = psnr(test_output[i:i+1], test_clean[i:i+1])\n",
    "        img_ssim = ssim(test_output[i:i+1], test_clean[i:i+1])\n",
    "        plt.text(0, -0.5, f'PSNR: {img_psnr:.2f} dB, SSIM: {img_ssim:.4f}', \n",
    "                transform=axes[i, 1].transAxes)\n",
    "    \n",
    "    plt.suptitle('Denoising results', size=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "#Calculate PSNR and SSIM for the best model on the validation set\n",
    "def evaluate_model(model, dataloader):\n",
    "    model.eval()\n",
    "    total_psnr = 0\n",
    "    total_ssim = 0\n",
    "    n_samples = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for noisy, clean in dataloader:\n",
    "            noisy, clean = noisy.to(DEVICE), clean.to(DEVICE)\n",
    "            output = model(noisy)\n",
    "            \n",
    "            total_psnr += psnr(output, clean) * len(noisy)\n",
    "            total_ssim += ssim(output, clean) * len(noisy)\n",
    "            n_samples += len(noisy)\n",
    "            \n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache()\n",
    "    \n",
    "    avg_psnr = total_psnr / n_samples\n",
    "    avg_ssim = total_ssim / n_samples\n",
    "    return avg_psnr, avg_ssim\n",
    "\n",
    "#Evaluate the best model on the validation set\n",
    "print('\\nCalculating PSNR and SSIM for the best model on the validation set...')\n",
    "val_psnr, val_ssim = evaluate_model(best_model, val_loader)\n",
    "print(f'Global metrics:')\n",
    "print(f'PSNR: {val_psnr:.2f} dB')\n",
    "print(f'SSIM: {val_ssim:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beaec9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import torchvision.transforms.functional as TF\n",
    "from datetime import datetime\n",
    "\n",
    "#Create a directory for saving results\n",
    "results_dir = 'denoised_results'\n",
    "if not os.path.exists(results_dir):\n",
    "    os.makedirs(results_dir)\n",
    "\n",
    "#Load the best model\n",
    "if 'best_model' not in locals():\n",
    "    best_model = load_best_model()\n",
    "best_model.eval()\n",
    "\n",
    "#Function to denoise a single image\n",
    "def denoise_image(image_path):\n",
    "    #Load and preprocess the image\n",
    "    img = Image.open(image_path).convert('RGB')\n",
    "    img = TF.resize(img, (IMAGE_SIZE, IMAGE_SIZE))\n",
    "    img_tensor = TF.to_tensor(img).unsqueeze(0).to(DEVICE)\n",
    "    \n",
    "    #Apply the model\n",
    "    with torch.no_grad():\n",
    "        with torch.cuda.amp.autocast():\n",
    "            denoised = best_model(img_tensor)\n",
    "    \n",
    "    #Convert back to PIL image\n",
    "    denoised = denoised.squeeze(0).cpu()\n",
    "    denoised = TF.to_pil_image(denoised)\n",
    "    return denoised\n",
    "\n",
    "#Process test images\n",
    "test_dir = 'Test_images'\n",
    "print('Processing test imagages...')\n",
    "\n",
    "test_results = []\n",
    "\n",
    "for img_name in os.listdir(test_dir):\n",
    "    if img_name.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "        img_path = os.path.join(test_dir, img_name)\n",
    "        print(f'Processing {img_name}...')\n",
    "        \n",
    "        #Process the image\n",
    "        denoised_img = denoise_image(img_path)\n",
    "        \n",
    "        #Save the denoised image\n",
    "        save_name = f'denoised_{img_name}'\n",
    "        save_path = os.path.join(results_dir, save_name)\n",
    "        denoised_img.save(save_path)\n",
    "        \n",
    "        #Keep for visualization\n",
    "        test_results.append((img_path, save_path))\n",
    "\n",
    "print(f'\\nResults saved at:  {results_dir}')\n",
    "\n",
    "#Visualize some results\n",
    "n_samples = min(4, len(test_results))\n",
    "if n_samples == 1:\n",
    "    #Case for a single image\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "    axes = np.array([[ax1, ax2]])  \n",
    "else:\n",
    "    #Case for multiple images\n",
    "    fig, axes = plt.subplots(n_samples, 2, figsize=(12, 3*n_samples))\n",
    "    axes = np.atleast_2d(axes) \n",
    "\n",
    "for idx, (noisy_path, denoised_path) in enumerate(test_results[:n_samples]):\n",
    "    #Show original noisy image\n",
    "    noisy_img = Image.open(noisy_path)\n",
    "    noisy_img = TF.resize(noisy_img, (IMAGE_SIZE, IMAGE_SIZE))\n",
    "    axes[idx, 0].imshow(noisy_img)\n",
    "    axes[idx, 0].set_title('Original')\n",
    "    axes[idx, 0].axis('off')\n",
    "    \n",
    "    #Show denoised image\n",
    "    denoised_img = Image.open(denoised_path)\n",
    "    axes[idx, 1].imshow(denoised_img)\n",
    "    axes[idx, 1].set_title('Denoised')\n",
    "    axes[idx, 1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
