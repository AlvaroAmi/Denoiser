{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c05651ec",
   "metadata": {},
   "source": [
    "# DENOISER\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974dee6b",
   "metadata": {},
   "source": [
    "## Dataset creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a844215",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "\n",
    "def get_sidd_image_pairs():\n",
    "    base_dir = 'test/Data'\n",
    "    image_pairs = []\n",
    "        \n",
    "    for subdir in os.listdir(base_dir):\n",
    "        subdir_path = os.path.join(base_dir, subdir)\n",
    "        if os.path.isdir(subdir_path):\n",
    "            gt_images = glob.glob(os.path.join(subdir_path, '*GT_SRGB*.PNG'))\n",
    "            for gt_path in gt_images:\n",
    "                noisy_path = gt_path.replace('GT_SRGB', 'NOISY_SRGB')\n",
    "                if os.path.exists(noisy_path):\n",
    "                    image_pairs.append((gt_path, noisy_path))\n",
    "    \n",
    "    return image_pairs\n",
    "\n",
    "data2_dir = 'data2'\n",
    "if not os.path.exists(data2_dir):\n",
    "    os.makedirs(data2_dir)\n",
    "\n",
    "clean_patches_dir = os.path.join(data2_dir, 'clean')\n",
    "noisy_patches_dir = os.path.join(data2_dir, 'noisy')\n",
    "\n",
    "if not os.path.exists(clean_patches_dir):\n",
    "    os.makedirs(clean_patches_dir)\n",
    "if not os.path.exists(noisy_patches_dir):\n",
    "    os.makedirs(noisy_patches_dir)\n",
    "\n",
    "processed_images_info = {}\n",
    "\n",
    "print('Searching for image pairs...')\n",
    "image_pairs = get_sidd_image_pairs()\n",
    "print(f'Found {len(image_pairs)} image pairs.')\n",
    "\n",
    "#Process each pair of images\n",
    "print('\\nProcessing images...')\n",
    "for clean_path, noisy_path in tqdm(image_pairs):\n",
    "    base_name = os.path.splitext(os.path.basename(clean_path))[0]\n",
    "    \n",
    "    #Process the clean image\n",
    "    patches, positions, patch_dims, original_size = create_patches(\n",
    "        clean_path,\n",
    "        output_dir=clean_patches_dir,\n",
    "        prefix=f'{base_name}_clean_')\n",
    "    \n",
    "    #Process the noisy image\n",
    "    create_patches(\n",
    "        noisy_path,\n",
    "        output_dir=noisy_patches_dir,\n",
    "        prefix=f'{base_name}_noisy_')\n",
    "    \n",
    "    processed_images_info[base_name] = {\n",
    "        'patch_positions': positions,\n",
    "        'patch_dimensions': patch_dims,\n",
    "        'original_size': original_size,\n",
    "        'clean_path': clean_path,\n",
    "        'noisy_path': noisy_path}\n",
    "    \n",
    "#Save the processing information to reconstruct later\n",
    "import json\n",
    "with open(os.path.join(data2_dir, 'processing_info.json'), 'w') as f:\n",
    "    json.dump(processed_images_info, f)\n",
    "\n",
    "print('\\nProcessing completed. Patches saved at:', data2_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f822cb",
   "metadata": {},
   "source": [
    "## UNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44d188de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import torchvision.transforms.functional as TF\n",
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from torchmetrics import PeakSignalNoiseRatio, StructuralSimilarityIndexMeasure\n",
    "import gc\n",
    "import json\n",
    "import torchvision.transforms as transforms\n",
    "from scipy.signal import windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2afd7e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 6  \n",
    "EPOCHS = 5\n",
    "LEARNING_RATE = 0.001\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "IMAGE_SIZE = 256\n",
    "CHECKPOINT_DIR = 'checkpoints'\n",
    "\n",
    "#Memory optimization configurations\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "if not os.path.exists(CHECKPOINT_DIR):\n",
    "    os.makedirs(CHECKPOINT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beaebd93",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenoisingDataset(Dataset):\n",
    "    def __init__(self, clean_dir, noisy_dir):\n",
    "        self.clean_dir = clean_dir\n",
    "        self.noisy_dir = noisy_dir\n",
    "        self.to_tensor = transforms.ToTensor()\n",
    "        \n",
    "        self.clean_patches = [f for f in os.listdir(clean_dir) if f.endswith('.png')]\n",
    "        self.clean_patches.sort() \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.clean_patches)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        clean_name = self.clean_patches[idx]\n",
    "        noisy_name = clean_name.replace('clean', 'noisy')\n",
    "        \n",
    "        clean_path = os.path.join(self.clean_dir, clean_name)\n",
    "        noisy_path = os.path.join(self.noisy_dir, noisy_name)\n",
    "        \n",
    "        clean_image = Image.open(clean_path).convert('RGB')\n",
    "        noisy_image = Image.open(noisy_path).convert('RGB')\n",
    "        \n",
    "        clean_image = self.to_tensor(clean_image)\n",
    "        noisy_image = self.to_tensor(noisy_image)\n",
    "        \n",
    "        return noisy_image, clean_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a87897",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, in_channels, 3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(in_channels)\n",
    "        self.conv2 = nn.Conv2d(in_channels, in_channels, 3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(in_channels)\n",
    "        self.relu = nn.LeakyReLU(0.2, inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += residual\n",
    "        return self.relu(out)\n",
    "\n",
    "class SpatialAttention(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, in_channels // 8, 1)\n",
    "        self.conv2 = nn.Conv2d(in_channels // 8, 1, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        attention = self.conv1(x)\n",
    "        attention = self.conv2(attention)\n",
    "        attention = self.sigmoid(attention)\n",
    "        return x * attention\n",
    "\n",
    "class EnhancedUNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.enc1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            ResidualBlock(64),\n",
    "            SpatialAttention(64)\n",
    "        )\n",
    "        \n",
    "        self.enc2 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, 3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            ResidualBlock(128),\n",
    "            SpatialAttention(128)\n",
    "        )\n",
    "        \n",
    "        self.enc3 = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, 3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            ResidualBlock(256),\n",
    "            SpatialAttention(256)\n",
    "        )\n",
    "        \n",
    "        self.enc4 = nn.Sequential(\n",
    "            nn.Conv2d(256, 512, 3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            ResidualBlock(512),\n",
    "            SpatialAttention(512)\n",
    "        )\n",
    "        \n",
    "        self.bottleneck = nn.Sequential(\n",
    "            nn.Conv2d(512, 1024, 3, padding=1),\n",
    "            nn.BatchNorm2d(1024),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            ResidualBlock(1024),\n",
    "            ResidualBlock(1024),\n",
    "            SpatialAttention(1024)\n",
    "        )\n",
    "        \n",
    "        self.dec4 = nn.Sequential(\n",
    "            nn.Conv2d(1024 + 512, 512, 3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            ResidualBlock(512),\n",
    "            SpatialAttention(512)\n",
    "        )\n",
    "        \n",
    "        self.dec3 = nn.Sequential(\n",
    "            nn.Conv2d(512 + 256, 256, 3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            ResidualBlock(256),\n",
    "            SpatialAttention(256)\n",
    "        )\n",
    "        \n",
    "        self.dec2 = nn.Sequential(\n",
    "            nn.Conv2d(256 + 128, 128, 3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            ResidualBlock(128),\n",
    "            SpatialAttention(128)\n",
    "        )\n",
    "        \n",
    "        self.dec1 = nn.Sequential(\n",
    "            nn.Conv2d(128 + 64, 64, 3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            ResidualBlock(64),\n",
    "            SpatialAttention(64)\n",
    "        )\n",
    "        \n",
    "        self.final = nn.Sequential(\n",
    "            nn.Conv2d(64, 32, 3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(32, 3, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "        self.upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        e1 = self.enc1(x)\n",
    "        e2 = self.enc2(self.pool(e1))\n",
    "        e3 = self.enc3(self.pool(e2))\n",
    "        e4 = self.enc4(self.pool(e3))\n",
    "        \n",
    "        b = self.bottleneck(self.pool(e4))\n",
    "        \n",
    "        d4 = self.dec4(torch.cat([self.upsample(b), e4], dim=1))\n",
    "        d3 = self.dec3(torch.cat([self.upsample(d4), e3], dim=1))\n",
    "        d2 = self.dec2(torch.cat([self.upsample(d3), e2], dim=1))\n",
    "        d1 = self.dec1(torch.cat([self.upsample(d2), e1], dim=1))\n",
    "        \n",
    "        return self.final(d1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def6a71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data preparation\n",
    "to_tensor = transforms.Compose([transforms.ToTensor(),])\n",
    "\n",
    "dataset = DenoisingDataset('data2/clean', 'data2/noisy')\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, pin_memory=True, num_workers=2)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, pin_memory=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628349ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EnhancedUNet().to(DEVICE)\n",
    "criterion = nn.L1Loss()  \n",
    "optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=1e-4)  \n",
    "\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5, verbose=True)\n",
    "\n",
    "#VRAM memory management optimization\n",
    "scaler = torch.cuda.amp.GradScaler('cuda')\n",
    "\n",
    "#Evaluation metrics\n",
    "psnr = PeakSignalNoiseRatio().to(DEVICE)\n",
    "ssim = StructuralSimilarityIndexMeasure().to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38842f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, train_loader, criterion, optimizer, scaler):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    total_psnr = 0\n",
    "    total_ssim = 0\n",
    "    \n",
    "    for noisy, clean in tqdm(train_loader):\n",
    "        noisy, clean = noisy.to(DEVICE), clean.to(DEVICE)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        with torch.amp.autocast('cuda'):\n",
    "            output = model(noisy)\n",
    "            loss = criterion(output, clean)\n",
    "        \n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            total_psnr += psnr(output, clean)\n",
    "            total_ssim += ssim(output, clean)\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "    \n",
    "    return total_loss / len(train_loader), total_psnr / len(train_loader), total_ssim / len(train_loader)\n",
    "\n",
    "@torch.no_grad()\n",
    "def validate(model, val_loader, criterion):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    total_psnr = 0\n",
    "    total_ssim = 0\n",
    "    \n",
    "    for noisy, clean in val_loader:\n",
    "        noisy, clean = noisy.to(DEVICE), clean.to(DEVICE)\n",
    "        \n",
    "        with torch.cuda.amp.autocast():\n",
    "            output = model(noisy)\n",
    "            loss = criterion(output, clean)\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        total_psnr += psnr(output, clean)\n",
    "        total_ssim += ssim(output, clean)\n",
    "        \n",
    "        #Clear CUDA cache to manage memory\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "    \n",
    "    return total_loss / len(val_loader), total_psnr / len(val_loader), total_ssim / len(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018e934a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gaussian_window(patch_size=256):\n",
    "    #Create a 1D Gaussian window\n",
    "    window = windows.gaussian(patch_size, patch_size/6)\n",
    "\n",
    "    #Convert to 2D Gaussian window\n",
    "    window_2d = np.outer(window, window)\n",
    "    window_2d = window_2d / window_2d.max()\n",
    "    \n",
    "    return window_2d\n",
    "\n",
    "def create_patches(image_path, patch_size=256, overlap=26, output_dir=None, prefix=''):\n",
    "    img = Image.open(image_path).convert('RGB')\n",
    "    width, height = img.size\n",
    "    \n",
    "    stride = patch_size - overlap\n",
    "    \n",
    "    n_patches_w = (width - overlap) // stride\n",
    "    n_patches_h = (height - overlap) // stride\n",
    "    \n",
    "    patches = []\n",
    "    patch_positions = []\n",
    "    \n",
    "    window = create_gaussian_window(patch_size)\n",
    "    \n",
    "    #Extract patches\n",
    "    for i in range(n_patches_h):\n",
    "        for j in range(n_patches_w):\n",
    "            left = j * stride\n",
    "            top = i * stride\n",
    "            right = left + patch_size\n",
    "            bottom = top + patch_size\n",
    "            \n",
    "            if right > width or bottom > height:\n",
    "                continue\n",
    "            \n",
    "            patch = img.crop((left, top, right, bottom))\n",
    "            \n",
    "            if output_dir:                \n",
    "                patch_name = f'{prefix}patch_{i}_{j}.png'\n",
    "                patch_path = os.path.join(output_dir, patch_name)\n",
    "                patch.save(patch_path)\n",
    "            \n",
    "            patches.append(patch)\n",
    "            patch_positions.append((left, top))\n",
    "    \n",
    "    return patches, patch_positions, (n_patches_h, n_patches_w), (width, height), window\n",
    "\n",
    "def reconstruct_image(patches, patch_positions, original_size, window, patch_size=256):\n",
    "    original_width, original_height = original_size\n",
    "    \n",
    "    #Create a blank image for reconstruction\n",
    "    reconstructed = np.zeros((original_height, original_width, 3))\n",
    "    weights = np.zeros((original_height, original_width))\n",
    "    \n",
    "    for patch, (left, top) in zip(patches, patch_positions):\n",
    "        patch_array = np.array(patch)\n",
    "        \n",
    "        #Apply the Gaussian window\n",
    "        for c in range(3):  \n",
    "            reconstructed[top:top+patch_size, left:left+patch_size, c] += \\\n",
    "                patch_array[:, :, c] * window\n",
    "        \n",
    "        #Accumulate weights\n",
    "        weights[top:top+patch_size, left:left+patch_size] += window\n",
    "    \n",
    "    weights = np.maximum(weights, 1e-10)\n",
    "    for c in range(3):\n",
    "        reconstructed[:, :, c] /= weights\n",
    "    \n",
    "    reconstructed = np.clip(reconstructed, 0, 255).astype(np.uint8)\n",
    "    reconstructed = Image.fromarray(reconstructed)\n",
    "    \n",
    "    return reconstructed\n",
    "\n",
    "def evaluate_full_images(model, device, processing_info_path='data2/processing_info.json'):\n",
    "    model.eval()\n",
    "    \n",
    "    if not os.path.exists('final_results'):\n",
    "        os.makedirs('final_results')\n",
    "    \n",
    "    with open(processing_info_path, 'r') as f:\n",
    "        processing_info = json.load(f)\n",
    "    \n",
    "    results = []\n",
    "    transform = transforms.ToTensor()\n",
    "    \n",
    "    for img_name, info in processing_info.items():\n",
    "        print(f'Processing image:  {img_name}...')\n",
    "        original_size = tuple(info['original_size'])\n",
    "        \n",
    "        base_path = info['noisy_path']\n",
    "        clean_path = info['clean_path']\n",
    "        \n",
    "        patches_noisy, positions, _, _, window = create_patches(base_path, output_dir=None)\n",
    "        patches_clean, _, _, _, _ = create_patches(clean_path, output_dir=None)\n",
    " \n",
    "        denoised_patches = []\n",
    "        with torch.no_grad():\n",
    "            for patch in patches_noisy:\n",
    "                patch_tensor = transform(patch).unsqueeze(0).to(device)\n",
    "                denoised_patch = model(patch_tensor)\n",
    "                denoised_patch = transforms.ToPILImage()(denoised_patch.squeeze().cpu())\n",
    "                denoised_patches.append(denoised_patch)\n",
    "        \n",
    "        #Reconstruct the full images\n",
    "        noisy_full = reconstruct_image(patches_noisy, positions, original_size, window)\n",
    "        clean_full = reconstruct_image(patches_clean, positions, original_size, window)\n",
    "        denoised_full = reconstruct_image(denoised_patches, positions, original_size, window)\n",
    "        \n",
    "        base_name = os.path.splitext(os.path.basename(base_path))[0]\n",
    "        noisy_save_path = os.path.join('final_results', f'{base_name}_noisy.png')\n",
    "        clean_save_path = os.path.join('final_results', f'{base_name}_clean.png')\n",
    "        denoised_save_path = os.path.join('final_results', f'{base_name}_denoised.png')\n",
    "        \n",
    "        noisy_full.save(noisy_save_path)\n",
    "        clean_full.save(clean_save_path)\n",
    "        denoised_full.save(denoised_save_path)\n",
    "        \n",
    "        #Calculate metrics\n",
    "        clean_tensor = transform(clean_full).unsqueeze(0).to(device)\n",
    "        denoised_tensor = transform(denoised_full).unsqueeze(0).to(device)\n",
    "        \n",
    "        psnr_val = psnr(denoised_tensor, clean_tensor)\n",
    "        ssim_val = ssim(denoised_tensor, clean_tensor)\n",
    "        \n",
    "        results.append({\n",
    "            'image_name': base_name,\n",
    "            'psnr': psnr_val.item(),\n",
    "            'ssim': ssim_val.item(),\n",
    "            'paths': {\n",
    "                'noisy': noisy_save_path,\n",
    "                'clean': clean_save_path,\n",
    "                'denoised': denoised_save_path\n",
    "            }\n",
    "        })\n",
    "        \n",
    "        print(f'PSNR: {psnr_val:.2f}, SSIM: {ssim_val:.4f}')\n",
    "    \n",
    "    with open('final_results/metrics.json', 'w') as f:\n",
    "        json.dump(results, f, indent=4)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d562b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------- Training loop --------------------\n",
    "best_val_loss = float('inf')\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "train_psnrs = []\n",
    "val_psnrs = []\n",
    "train_ssims = []\n",
    "val_ssims = []\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    train_loss, train_psnr_val, train_ssim_val = train_epoch(model, train_loader, criterion, optimizer, scaler)\n",
    "    val_loss, val_psnr_val, val_ssim_val = validate(model, val_loader, criterion)\n",
    "    \n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    train_psnrs.append(train_psnr_val)\n",
    "    val_psnrs.append(val_psnr_val)\n",
    "    train_ssims.append(train_ssim_val)\n",
    "    val_ssims.append(val_ssim_val)\n",
    "    \n",
    "    print(f'Epoch {epoch+1}/{EPOCHS}:')\n",
    "    print(f'Train Loss: {train_loss:.6f}, Train PSNR: {train_psnr_val:.2f}, Train SSIM: {train_ssim_val:.4f}')\n",
    "    print(f'Val Loss: {val_loss:.6f}, Val PSNR: {val_psnr_val:.2f}, Val SSIM: {val_ssim_val:.4f}')\n",
    "    \n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'val_loss': val_loss,\n",
    "        }, f'{CHECKPOINT_DIR}/best_model.pth')\n",
    "    \n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'val_loss': val_loss,\n",
    "    }, f'{CHECKPOINT_DIR}/checkpoint_epoch_{epoch+1}.pth')\n",
    "                \n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "\n",
    "print('\\nTraining completed, evaluating on full images...')\n",
    "final_results = evaluate_full_images(model, DEVICE)\n",
    "\n",
    "def show_final_results(results, num_samples=4):\n",
    "    num_samples = min(num_samples, len(results))\n",
    "    fig, axes = plt.subplots(num_samples, 3, figsize=(15, 5*num_samples))\n",
    "    \n",
    "    for i, result in enumerate(results[:num_samples]):\n",
    "        noisy = Image.open(result['paths']['noisy'])\n",
    "        clean = Image.open(result['paths']['clean'])\n",
    "        denoised = Image.open(result['paths']['denoised'])\n",
    "        \n",
    "        axes[i, 0].imshow(noisy)\n",
    "        axes[i, 0].set_title('Noisy')\n",
    "        axes[i, 0].axis('off')\n",
    "        \n",
    "        axes[i, 1].imshow(denoised)\n",
    "        axes[i, 1].set_title(f'Denoised\\nPSNR: {result[\"psnr\"]:.2f}, SSIM: {result[\"ssim\"]:.4f}')\n",
    "        axes[i, 1].axis('off')\n",
    "        \n",
    "        axes[i, 2].imshow(clean)\n",
    "        axes[i, 2].set_title('Clean')\n",
    "        axes[i, 2].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "show_final_results(final_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667ab700",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load and evaluate the best model\n",
    "import os\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import json\n",
    "from torchvision import transforms\n",
    "\n",
    "BEST_MODEL_PATH = os.path.join(CHECKPOINT_DIR, 'best_model.pth')\n",
    "\n",
    "if os.path.exists(BEST_MODEL_PATH):\n",
    "    print(f'Loading best model from {BEST_MODEL_PATH}')\n",
    "    \n",
    "    best_model = EnhancedUNet().to(DEVICE)\n",
    "    \n",
    "    #Load the best model checkpoint\n",
    "    checkpoint = torch.load(BEST_MODEL_PATH, map_location=DEVICE)\n",
    "    best_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    best_epoch = checkpoint['epoch']\n",
    "    best_val_loss = checkpoint['val_loss']\n",
    "    \n",
    "    print(f'Best model from epoch {best_epoch+1} with validation loss {best_val_loss:.6f}')\n",
    "    \n",
    "    best_model.eval()\n",
    "    \n",
    "    BEST_RESULTS_DIR = 'best_model_results'\n",
    "    if not os.path.exists(BEST_RESULTS_DIR):\n",
    "        os.makedirs(BEST_RESULTS_DIR)\n",
    "    \n",
    "    #Evaluate the best model on full images\n",
    "    print('\\nEvaluating the best model with full images...')\n",
    "    best_results = evaluate_full_images(best_model, DEVICE)\n",
    "    \n",
    "    for result in best_results:\n",
    "        base_name = os.path.basename(result['paths']['denoised'])\n",
    "        new_path = os.path.join(BEST_RESULTS_DIR, base_name)\n",
    "        img = Image.open(result['paths']['denoised'])\n",
    "        img.save(new_path)\n",
    "        \n",
    "        result['paths']['best_denoised'] = new_path\n",
    "    \n",
    "    with open(os.path.join(BEST_RESULTS_DIR, 'best_model_metrics.json'), 'w') as f:\n",
    "        json.dump(best_results, f, indent=4)\n",
    "    \n",
    "    print('\\nShowing best model results:')\n",
    "    show_final_results(best_results)\n",
    "    \n",
    "    #Compare best model with final model\n",
    "    def compare_models_results(final_results, best_results, num_samples=2):\n",
    "        num_samples = min(num_samples, len(final_results), len(best_results))\n",
    "        fig, axes = plt.subplots(num_samples, 4, figsize=(20, 5*num_samples))\n",
    "        \n",
    "        for i in range(num_samples):\n",
    "            final_result = final_results[i]\n",
    "            best_result = best_results[i]\n",
    "            \n",
    "            noisy = Image.open(final_result['paths']['noisy'])\n",
    "            clean = Image.open(final_result['paths']['clean'])\n",
    "            final_denoised = Image.open(final_result['paths']['denoised'])\n",
    "            best_denoised = Image.open(best_result['paths']['denoised'])\n",
    "            \n",
    "            axes[i, 0].imshow(noisy)\n",
    "            axes[i, 0].set_title('Noisy')\n",
    "            axes[i, 0].axis('off')\n",
    "            \n",
    "            axes[i, 1].imshow(best_denoised)\n",
    "            axes[i, 1].set_title(f'Best Model\\nPSNR: {best_result[\"psnr\"]:.2f}, SSIM: {best_result[\"ssim\"]:.4f}')\n",
    "            axes[i, 1].axis('off')\n",
    "            \n",
    "            axes[i, 2].imshow(final_denoised)\n",
    "            axes[i, 2].set_title(f'Final Model\\nPSNR: {final_result[\"psnr\"]:.2f}, SSIM: {final_result[\"ssim\"]:.4f}')\n",
    "            axes[i, 2].axis('off')\n",
    "            \n",
    "            axes[i, 3].imshow(clean)\n",
    "            axes[i, 3].set_title('Clean')\n",
    "            axes[i, 3].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(BEST_RESULTS_DIR, 'model_comparison.png'))\n",
    "        plt.show()\n",
    "    \n",
    "    print('\\nComparing best model with final model:')\n",
    "    compare_models_results(final_results, best_results)\n",
    "    \n",
    "    #Calculate and print average metrics\n",
    "    final_avg_psnr = sum(r['psnr'] for r in final_results) / len(final_results)\n",
    "    final_avg_ssim = sum(r['ssim'] for r in final_results) / len(final_results)\n",
    "    best_avg_psnr = sum(r['psnr'] for r in best_results) / len(best_results)\n",
    "    best_avg_ssim = sum(r['ssim'] for r in best_results) / len(best_results)\n",
    "    \n",
    "    print('\\nAverage Metrics:')\n",
    "    print(f'Final Model - PSNR: {final_avg_psnr:.2f}, SSIM: {final_avg_ssim:.4f}')\n",
    "    print(f'Best Model - PSNR: {best_avg_psnr:.2f}, SSIM: {best_avg_ssim:.4f}')\n",
    "\n",
    "    def test_external_images(model, device, test_dir='Test_images', output_dir='external_test_results'):\n",
    "        if not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir)\n",
    "        \n",
    "        test_files = [f for f in os.listdir(test_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "        transform = transforms.Compose([\n",
    "            transforms.ToTensor(),])\n",
    "        \n",
    "        results = []\n",
    "        \n",
    "        for img_file in test_files:\n",
    "            img_path = os.path.join(test_dir, img_file)\n",
    "            \n",
    "            img = Image.open(img_path).convert('RGB')\n",
    "            \n",
    "            patches, positions, _, original_size, window = create_patches(img_path, output_dir=None)\n",
    "            \n",
    "            denoised_patches = []\n",
    "            with torch.no_grad():\n",
    "                for patch in patches:\n",
    "                    patch_tensor = transform(patch).unsqueeze(0).to(device)\n",
    "                    denoised_patch = model(patch_tensor)\n",
    "                    denoised_patch = transforms.ToPILImage()(denoised_patch.squeeze().cpu())\n",
    "                    denoised_patches.append(denoised_patch)\n",
    "            \n",
    "            denoised_full = reconstruct_image(denoised_patches, positions, original_size, window)\n",
    "\n",
    "            base_name = os.path.splitext(img_file)[0]\n",
    "            denoised_save_path = os.path.join(output_dir, f'{base_name}_denoised.png')\n",
    "            \n",
    "            denoised_full.save(denoised_save_path)\n",
    "            \n",
    "            results.append({\n",
    "                'image_name': base_name,\n",
    "                'original_path': img_path,\n",
    "                'denoised_path': denoised_save_path})\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    if os.path.exists('Test_images') and any(f.lower().endswith(('.png', '.jpg', '.jpeg')) for f in os.listdir('Test_images')):\n",
    "        external_results = test_external_images(best_model, DEVICE)\n",
    "        \n",
    "        def show_external_results(results, num_samples=4):\n",
    "            num_samples = min(num_samples, len(results))\n",
    "            fig, axes = plt.subplots(num_samples, 2, figsize=(10, 5*num_samples))\n",
    "            \n",
    "            if num_samples == 1:\n",
    "                axes = [axes]\n",
    "            \n",
    "            for i, result in enumerate(results[:num_samples]):\n",
    "                noisy = Image.open(result['original_path'])\n",
    "                denoised = Image.open(result['denoised_path'])\n",
    "                \n",
    "                axes[i, 0].imshow(noisy)\n",
    "                axes[i, 0].set_title('Original')\n",
    "                axes[i, 0].axis('off')\n",
    "                \n",
    "                axes[i, 1].imshow(denoised)\n",
    "                axes[i, 1].set_title('Denoised')\n",
    "                axes[i, 1].axis('off')\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.savefig('external_test_results/external_results.png')\n",
    "            plt.show()\n",
    "        \n",
    "        if external_results:\n",
    "            show_external_results(external_results)\n",
    "    \n",
    "else:\n",
    "    print(f'Error: Best model not found at {BEST_MODEL_PATH}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
