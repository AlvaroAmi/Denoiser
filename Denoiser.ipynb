{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c05651ec",
   "metadata": {},
   "source": [
    "# DENOISER\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974dee6b",
   "metadata": {},
   "source": [
    "## Dataset creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a844215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for image pairs...\n",
      "Found 310 image pairs.\n",
      "\n",
      "Processing images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 310/310 [39:57<00:00,  7.73s/it]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing completed. Patches saved at: data2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "\n",
    "def get_sidd_image_pairs():\n",
    "    base_dir = 'test/Data'\n",
    "    image_pairs = []\n",
    "        \n",
    "    for subdir in os.listdir(base_dir):\n",
    "        subdir_path = os.path.join(base_dir, subdir)\n",
    "        if os.path.isdir(subdir_path):\n",
    "            gt_images = glob.glob(os.path.join(subdir_path, '*GT_SRGB*.PNG'))\n",
    "            for gt_path in gt_images:\n",
    "                noisy_path = gt_path.replace('GT_SRGB', 'NOISY_SRGB')\n",
    "                if os.path.exists(noisy_path):\n",
    "                    image_pairs.append((gt_path, noisy_path))\n",
    "    \n",
    "    return image_pairs\n",
    "\n",
    "data2_dir = 'data2'\n",
    "if not os.path.exists(data2_dir):\n",
    "    os.makedirs(data2_dir)\n",
    "\n",
    "clean_patches_dir = os.path.join(data2_dir, 'clean')\n",
    "noisy_patches_dir = os.path.join(data2_dir, 'noisy')\n",
    "\n",
    "if not os.path.exists(clean_patches_dir):\n",
    "    os.makedirs(clean_patches_dir)\n",
    "if not os.path.exists(noisy_patches_dir):\n",
    "    os.makedirs(noisy_patches_dir)\n",
    "\n",
    "processed_images_info = {}\n",
    "\n",
    "print('Searching for image pairs...')\n",
    "image_pairs = get_sidd_image_pairs()\n",
    "print(f'Found {len(image_pairs)} image pairs.')\n",
    "\n",
    "#Process each pair of images\n",
    "print('\\nProcessing images...')\n",
    "for clean_path, noisy_path in tqdm(image_pairs):\n",
    "    base_name = os.path.splitext(os.path.basename(clean_path))[0]\n",
    "    \n",
    "    #Process the clean image\n",
    "    patches, positions, patch_dims, original_size, window = create_patches(\n",
    "        clean_path,\n",
    "        output_dir=clean_patches_dir,\n",
    "        prefix=f'{base_name}_clean_')\n",
    "    \n",
    "    #Process the noisy image\n",
    "    create_patches(\n",
    "        noisy_path,\n",
    "        output_dir=noisy_patches_dir,\n",
    "        prefix=f'{base_name}_noisy_')\n",
    "    \n",
    "    processed_images_info[base_name] = {\n",
    "        'patch_positions': positions,\n",
    "        'patch_dimensions': patch_dims,\n",
    "        'original_size': original_size,\n",
    "        'clean_path': clean_path,\n",
    "        'noisy_path': noisy_path}\n",
    "    \n",
    "#Save the processing information to reconstruct later\n",
    "import json\n",
    "with open(os.path.join(data2_dir, 'processing_info.json'), 'w') as f:\n",
    "    json.dump(processed_images_info, f)\n",
    "\n",
    "print('\\nProcessing completed. Patches saved at:', data2_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f822cb",
   "metadata": {},
   "source": [
    "## UNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "44d188de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import torchvision.transforms.functional as TF\n",
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from torchmetrics import PeakSignalNoiseRatio, StructuralSimilarityIndexMeasure\n",
    "import gc\n",
    "import json\n",
    "import torchvision.transforms as transforms\n",
    "from scipy.signal import windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2afd7e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 6  \n",
    "EPOCHS = 5\n",
    "LEARNING_RATE = 0.001\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "IMAGE_SIZE = 256\n",
    "CHECKPOINT_DIR = 'checkpoints'\n",
    "\n",
    "#Memory optimization configurations\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "if not os.path.exists(CHECKPOINT_DIR):\n",
    "    os.makedirs(CHECKPOINT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "beaebd93",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenoisingDataset(Dataset):\n",
    "    def __init__(self, clean_dir, noisy_dir):\n",
    "        self.clean_dir = clean_dir\n",
    "        self.noisy_dir = noisy_dir\n",
    "        self.to_tensor = transforms.ToTensor()\n",
    "        \n",
    "        self.clean_patches = [f for f in os.listdir(clean_dir) if f.endswith('.png')]\n",
    "        self.clean_patches.sort() \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.clean_patches)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        clean_name = self.clean_patches[idx]\n",
    "        noisy_name = clean_name.replace('clean', 'noisy')\n",
    "        \n",
    "        clean_path = os.path.join(self.clean_dir, clean_name)\n",
    "        noisy_path = os.path.join(self.noisy_dir, noisy_name)\n",
    "        \n",
    "        clean_image = Image.open(clean_path).convert('RGB')\n",
    "        noisy_image = Image.open(noisy_path).convert('RGB')\n",
    "        \n",
    "        clean_image = self.to_tensor(clean_image)\n",
    "        noisy_image = self.to_tensor(noisy_image)\n",
    "        \n",
    "        return noisy_image, clean_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e4a87897",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, in_channels, 3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(in_channels)\n",
    "        self.conv2 = nn.Conv2d(in_channels, in_channels, 3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(in_channels)\n",
    "        self.relu = nn.LeakyReLU(0.2, inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += residual\n",
    "        return self.relu(out)\n",
    "\n",
    "class SpatialAttention(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, in_channels // 8, 1)\n",
    "        self.conv2 = nn.Conv2d(in_channels // 8, 1, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        attention = self.conv1(x)\n",
    "        attention = self.conv2(attention)\n",
    "        attention = self.sigmoid(attention)\n",
    "        return x * attention\n",
    "\n",
    "class EnhancedUNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.enc1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            ResidualBlock(64),\n",
    "            SpatialAttention(64)\n",
    "        )\n",
    "        \n",
    "        self.enc2 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, 3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            ResidualBlock(128),\n",
    "            SpatialAttention(128)\n",
    "        )\n",
    "        \n",
    "        self.enc3 = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, 3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            ResidualBlock(256),\n",
    "            SpatialAttention(256)\n",
    "        )\n",
    "        \n",
    "        self.enc4 = nn.Sequential(\n",
    "            nn.Conv2d(256, 512, 3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            ResidualBlock(512),\n",
    "            SpatialAttention(512)\n",
    "        )\n",
    "        \n",
    "        self.bottleneck = nn.Sequential(\n",
    "            nn.Conv2d(512, 1024, 3, padding=1),\n",
    "            nn.BatchNorm2d(1024),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            ResidualBlock(1024),\n",
    "            ResidualBlock(1024),\n",
    "            SpatialAttention(1024)\n",
    "        )\n",
    "        \n",
    "        self.dec4 = nn.Sequential(\n",
    "            nn.Conv2d(1024 + 512, 512, 3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            ResidualBlock(512),\n",
    "            SpatialAttention(512)\n",
    "        )\n",
    "        \n",
    "        self.dec3 = nn.Sequential(\n",
    "            nn.Conv2d(512 + 256, 256, 3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            ResidualBlock(256),\n",
    "            SpatialAttention(256)\n",
    "        )\n",
    "        \n",
    "        self.dec2 = nn.Sequential(\n",
    "            nn.Conv2d(256 + 128, 128, 3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            ResidualBlock(128),\n",
    "            SpatialAttention(128)\n",
    "        )\n",
    "        \n",
    "        self.dec1 = nn.Sequential(\n",
    "            nn.Conv2d(128 + 64, 64, 3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            ResidualBlock(64),\n",
    "            SpatialAttention(64)\n",
    "        )\n",
    "        \n",
    "        self.final = nn.Sequential(\n",
    "            nn.Conv2d(64, 32, 3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(32, 3, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "        self.upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        e1 = self.enc1(x)\n",
    "        e2 = self.enc2(self.pool(e1))\n",
    "        e3 = self.enc3(self.pool(e2))\n",
    "        e4 = self.enc4(self.pool(e3))\n",
    "        \n",
    "        b = self.bottleneck(self.pool(e4))\n",
    "        \n",
    "        d4 = self.dec4(torch.cat([self.upsample(b), e4], dim=1))\n",
    "        d3 = self.dec3(torch.cat([self.upsample(d4), e3], dim=1))\n",
    "        d2 = self.dec2(torch.cat([self.upsample(d3), e2], dim=1))\n",
    "        d1 = self.dec1(torch.cat([self.upsample(d2), e1], dim=1))\n",
    "        \n",
    "        return self.final(d1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "def6a71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data preparation\n",
    "to_tensor = transforms.Compose([transforms.ToTensor(),])\n",
    "\n",
    "dataset = DenoisingDataset('data2/clean', 'data2/noisy')\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, pin_memory=True, num_workers=2)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, pin_memory=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "628349ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_107835/2384045932.py:8: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler()\n"
     ]
    }
   ],
   "source": [
    "model = EnhancedUNet().to(DEVICE)\n",
    "criterion = nn.L1Loss()  \n",
    "optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=1e-4)  \n",
    "\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5, verbose=True)\n",
    "\n",
    "#VRAM memory management optimization\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "#Evaluation metrics\n",
    "psnr = PeakSignalNoiseRatio().to(DEVICE)\n",
    "ssim = StructuralSimilarityIndexMeasure().to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "38842f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, train_loader, criterion, optimizer, scaler):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    total_psnr = 0\n",
    "    total_ssim = 0\n",
    "    \n",
    "    for noisy, clean in tqdm(train_loader):\n",
    "        noisy, clean = noisy.to(DEVICE), clean.to(DEVICE)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        with torch.amp.autocast('cuda'):\n",
    "            output = model(noisy)\n",
    "            loss = criterion(output, clean)\n",
    "        \n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            total_psnr += psnr(output, clean)\n",
    "            total_ssim += ssim(output, clean)\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "    \n",
    "    return total_loss / len(train_loader), total_psnr / len(train_loader), total_ssim / len(train_loader)\n",
    "\n",
    "@torch.no_grad()\n",
    "def validate(model, val_loader, criterion):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    total_psnr = 0\n",
    "    total_ssim = 0\n",
    "    \n",
    "    for noisy, clean in val_loader:\n",
    "        noisy, clean = noisy.to(DEVICE), clean.to(DEVICE)\n",
    "        \n",
    "        with torch.cuda.amp.autocast():\n",
    "            output = model(noisy)\n",
    "            loss = criterion(output, clean)\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        total_psnr += psnr(output, clean)\n",
    "        total_ssim += ssim(output, clean)\n",
    "        \n",
    "        #Clear CUDA cache to manage memory\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "    \n",
    "    return total_loss / len(val_loader), total_psnr / len(val_loader), total_ssim / len(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018e934a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gaussian_window(patch_size=256):\n",
    "    #Create a 1D Gaussian window\n",
    "    window = windows.gaussian(patch_size, patch_size/6)\n",
    "\n",
    "    #Convert to 2D Gaussian window\n",
    "    window_2d = np.outer(window, window)\n",
    "    window_2d = window_2d / window_2d.max()\n",
    "    \n",
    "    return window_2d\n",
    "\n",
    "def create_patches(image_path, patch_size=256, overlap=26, output_dir=None, prefix=''):\n",
    "    img = Image.open(image_path).convert('RGB')\n",
    "    width, height = img.size\n",
    "    \n",
    "    stride = patch_size - overlap\n",
    "    \n",
    "    n_patches_w = (width - overlap) // stride\n",
    "    n_patches_h = (height - overlap) // stride\n",
    "    \n",
    "    patches = []\n",
    "    patch_positions = []\n",
    "    \n",
    "    window = create_gaussian_window(patch_size)\n",
    "    \n",
    "    #Extract patches\n",
    "    for i in range(n_patches_h):\n",
    "        for j in range(n_patches_w):\n",
    "            left = j * stride\n",
    "            top = i * stride\n",
    "            right = left + patch_size\n",
    "            bottom = top + patch_size\n",
    "            \n",
    "            if right > width or bottom > height:\n",
    "                continue\n",
    "            \n",
    "            patch = img.crop((left, top, right, bottom))\n",
    "            \n",
    "            if output_dir:                \n",
    "                patch_name = f'{prefix}patch_{i}_{j}.png'\n",
    "                patch_path = os.path.join(output_dir, patch_name)\n",
    "                patch.save(patch_path)\n",
    "            \n",
    "            patches.append(patch)\n",
    "            patch_positions.append((left, top))\n",
    "    \n",
    "    return patches, patch_positions, (n_patches_h, n_patches_w), (width, height), window\n",
    "\n",
    "def reconstruct_image(patches, patch_positions, original_size, window, patch_size=256):\n",
    "    original_width, original_height = original_size\n",
    "    \n",
    "    #Create a blank image for reconstruction\n",
    "    reconstructed = np.zeros((original_height, original_width, 3))\n",
    "    weights = np.zeros((original_height, original_width))\n",
    "    \n",
    "    for patch, (left, top) in zip(patches, patch_positions):\n",
    "        patch_array = np.array(patch)\n",
    "        \n",
    "        #Apply the Gaussian window\n",
    "        for c in range(3):  \n",
    "            reconstructed[top:top+patch_size, left:left+patch_size, c] += \\\n",
    "                patch_array[:, :, c] * window\n",
    "        \n",
    "        #Accumulate weights\n",
    "        weights[top:top+patch_size, left:left+patch_size] += window\n",
    "    \n",
    "    weights = np.maximum(weights, 1e-10)\n",
    "    for c in range(3):\n",
    "        reconstructed[:, :, c] /= weights\n",
    "    \n",
    "    reconstructed = np.clip(reconstructed, 0, 255).astype(np.uint8)\n",
    "    reconstructed = Image.fromarray(reconstructed)\n",
    "    \n",
    "    return reconstructed\n",
    "\n",
    "def evaluate_full_images(model, device, processing_info_path='data2/processing_info.json'):\n",
    "    model.eval()\n",
    "    \n",
    "    if not os.path.exists('final_results'):\n",
    "        os.makedirs('final_results')\n",
    "    \n",
    "    with open(processing_info_path, 'r') as f:\n",
    "        processing_info = json.load(f)\n",
    "    \n",
    "    results = []\n",
    "    transform = transforms.ToTensor()\n",
    "    \n",
    "    for img_name, info in processing_info.items():\n",
    "        print(f'Processing image:  {img_name}...')\n",
    "        original_size = tuple(info['original_size'])\n",
    "        \n",
    "        base_path = info['noisy_path']\n",
    "        clean_path = info['clean_path']\n",
    "        \n",
    "        patches_noisy, positions, _, _, window = create_patches(base_path, output_dir=None)\n",
    "        patches_clean, _, _, _, _ = create_patches(clean_path, output_dir=None)\n",
    " \n",
    "        denoised_patches = []\n",
    "        with torch.no_grad():\n",
    "            for patch in patches_noisy:\n",
    "                patch_tensor = transform(patch).unsqueeze(0).to(device)\n",
    "                denoised_patch = model(patch_tensor)\n",
    "                denoised_patch = transforms.ToPILImage()(denoised_patch.squeeze().cpu())\n",
    "                denoised_patches.append(denoised_patch)\n",
    "        \n",
    "        #Reconstruct the full images\n",
    "        noisy_full = reconstruct_image(patches_noisy, positions, original_size, window)\n",
    "        clean_full = reconstruct_image(patches_clean, positions, original_size, window)\n",
    "        denoised_full = reconstruct_image(denoised_patches, positions, original_size, window)\n",
    "        \n",
    "        base_name = os.path.splitext(os.path.basename(base_path))[0]\n",
    "        noisy_save_path = os.path.join('final_results', f'{base_name}_noisy.png')\n",
    "        clean_save_path = os.path.join('final_results', f'{base_name}_clean.png')\n",
    "        denoised_save_path = os.path.join('final_results', f'{base_name}_denoised.png')\n",
    "        \n",
    "        noisy_full.save(noisy_save_path)\n",
    "        clean_full.save(clean_save_path)\n",
    "        denoised_full.save(denoised_save_path)\n",
    "        \n",
    "        #Calculate metrics\n",
    "        clean_tensor = transform(clean_full).unsqueeze(0).to(device)\n",
    "        denoised_tensor = transform(denoised_full).unsqueeze(0).to(device)\n",
    "        \n",
    "        psnr_val = psnr(denoised_tensor, clean_tensor)\n",
    "        ssim_val = ssim(denoised_tensor, clean_tensor)\n",
    "        \n",
    "        results.append({\n",
    "            'image_name': base_name,\n",
    "            'psnr': psnr_val.item(),\n",
    "            'ssim': ssim_val.item(),\n",
    "            'paths': {\n",
    "                'noisy': noisy_save_path,\n",
    "                'clean': clean_save_path,\n",
    "                'denoised': denoised_save_path\n",
    "            }\n",
    "        })\n",
    "        \n",
    "        print(f'PSNR: {psnr_val:.2f}, SSIM: {ssim_val:.4f}')\n",
    "    \n",
    "    with open('final_results/metrics.json', 'w') as f:\n",
    "        json.dump(results, f, indent=4)\n",
    "    \n",
    "    return results\n",
    "\n",
    "def evaluate_validation_images(model, device):\n",
    "    model.eval()\n",
    "    eval_results = []\n",
    "    transform = transforms.ToTensor()\n",
    "    \n",
    "    clean_dir = 'evaluation/clean'\n",
    "    noisy_dir = 'evaluation/noisy'\n",
    "    \n",
    "    if not os.path.exists(clean_dir):\n",
    "        print(f\"Error: not found {clean_dir}\")\n",
    "        return 0.0, 0.0\n",
    "    if not os.path.exists(noisy_dir):\n",
    "        print(f\"Error: Not found {noisy_dir}\")\n",
    "        return 0.0, 0.0\n",
    "    \n",
    "    print(f\"\\nBuscando imágenes en {noisy_dir}...\")\n",
    "    noisy_images = [f for f in os.listdir(noisy_dir) if f.endswith(('.png', '.PNG', '.jpg', '.jpeg'))]\n",
    "    \n",
    "    if not noisy_images:\n",
    "        print(f\"Error: No images found at {noisy_dir}\")\n",
    "        return 0.0, 0.0\n",
    "    \n",
    "    print(f\"Found {len(noisy_images)} images for evaluation.\")\n",
    "    valid_pairs = 0\n",
    "    \n",
    "    for img_name in noisy_images:\n",
    "        noisy_path = os.path.join(noisy_dir, img_name)\n",
    "        clean_path = os.path.join(clean_dir, img_name)\n",
    "        \n",
    "        if not os.path.exists(clean_path):\n",
    "            print(f\"No clean image found for {img_name}\")\n",
    "            continue\n",
    "            \n",
    "        patches_noisy, positions, _, original_size, window = create_patches(noisy_path, output_dir=None)\n",
    "        patches_clean, _, _, _, _ = create_patches(clean_path, output_dir=None)\n",
    "\n",
    "        denoised_patches = []\n",
    "        with torch.no_grad():\n",
    "            for patch in patches_noisy:\n",
    "                patch_tensor = transform(patch).unsqueeze(0).to(device)\n",
    "                denoised_patch = model(patch_tensor)\n",
    "                denoised_patch = transforms.ToPILImage()(denoised_patch.squeeze().cpu())\n",
    "                denoised_patches.append(denoised_patch)\n",
    "        \n",
    "        noisy_full = reconstruct_image(patches_noisy, positions, original_size, window)\n",
    "        clean_full = reconstruct_image(patches_clean, positions, original_size, window)\n",
    "        denoised_full = reconstruct_image(denoised_patches, positions, original_size, window)\n",
    "        \n",
    "        clean_tensor = transform(clean_full).unsqueeze(0).to(device)\n",
    "        denoised_tensor = transform(denoised_full).unsqueeze(0).to(device)\n",
    "        \n",
    "        img_psnr = psnr(denoised_tensor, clean_tensor)\n",
    "        img_ssim = ssim(denoised_tensor, clean_tensor)\n",
    "        \n",
    "        try:\n",
    "            eval_results.append({\n",
    "                'psnr': img_psnr.item(),\n",
    "                'ssim': img_ssim.item()\n",
    "            })\n",
    "            valid_pairs += 1\n",
    "            print(f\"Processed image {valid_pairs}/{len(noisy_images)}: {img_name}\")\n",
    "            print(f\"PSNR: {img_psnr.item():.2f}, SSIM: {img_ssim.item():.4f}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {img_name}: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    if not eval_results:\n",
    "        print(\"No images were processed successfully.\")\n",
    "        return 0.0, 0.0\n",
    "        \n",
    "    avg_psnr = sum(r['psnr'] for r in eval_results) / len(eval_results)\n",
    "    avg_ssim = sum(r['ssim'] for r in eval_results) / len(eval_results)\n",
    "    \n",
    "    print(f\"PSNR avg: {avg_psnr:.2f}\")\n",
    "    print(f\"SSIM avg: {avg_ssim:.4f}\")\n",
    "    \n",
    "    return avg_psnr, avg_ssim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9d562b9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/9901 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/9901 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9901/9901 [26:07<00:00,  6.32it/s]\n",
      "100%|██████████| 9901/9901 [26:07<00:00,  6.32it/s]\n",
      "/tmp/ipykernel_107835/365605072.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/tmp/ipykernel_107835/365605072.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/9901 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9901/9901 [26:07<00:00,  6.32it/s]\n",
      "100%|██████████| 9901/9901 [26:07<00:00,  6.32it/s]\n",
      "/tmp/ipykernel_107835/365605072.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/tmp/ipykernel_107835/365605072.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m train_loss, train_psnr_val, train_ssim_val \u001b[38;5;241m=\u001b[39m train_epoch(model, train_loader, criterion, optimizer, scaler)\n\u001b[1;32m     15\u001b[0m val_loss, val_psnr_val, val_ssim_val \u001b[38;5;241m=\u001b[39m validate(model, val_loader, criterion)\n\u001b[0;32m---> 17\u001b[0m eval_psnr, eval_ssim \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_validation_images\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m train_losses\u001b[38;5;241m.\u001b[39mappend(train_loss)\n\u001b[1;32m     20\u001b[0m val_losses\u001b[38;5;241m.\u001b[39mappend(val_loss)\n",
      "Cell \u001b[0;32mIn[23], line 187\u001b[0m, in \u001b[0;36mevaluate_validation_images\u001b[0;34m(model, device)\u001b[0m\n\u001b[1;32m    180\u001b[0m     img_ssim \u001b[38;5;241m=\u001b[39m ssim(denoised_tensor, clean_tensor)\n\u001b[1;32m    182\u001b[0m     eval_results\u001b[38;5;241m.\u001b[39mappend({\n\u001b[1;32m    183\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpsnr\u001b[39m\u001b[38;5;124m'\u001b[39m: img_psnr\u001b[38;5;241m.\u001b[39mitem(),\n\u001b[1;32m    184\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mssim\u001b[39m\u001b[38;5;124m'\u001b[39m: img_ssim\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m    185\u001b[0m     })\n\u001b[0;32m--> 187\u001b[0m avg_psnr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mr\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpsnr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mr\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43meval_results\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43meval_results\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    188\u001b[0m avg_ssim \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(r[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mssim\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m eval_results) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(eval_results)\n\u001b[1;32m    190\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m avg_psnr, avg_ssim\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "#-------------------- Training loop --------------------\n",
    "best_val_loss = float('inf')\n",
    "best_eval_psnr = 0\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "train_psnrs = []\n",
    "val_psnrs = []\n",
    "train_ssims = []\n",
    "val_ssims = []\n",
    "eval_psnrs = []\n",
    "eval_ssims = []\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    train_loss, train_psnr_val, train_ssim_val = train_epoch(model, train_loader, criterion, optimizer, scaler)\n",
    "    val_loss, val_psnr_val, val_ssim_val = validate(model, val_loader, criterion)\n",
    "    \n",
    "    eval_psnr, eval_ssim = evaluate_validation_images(model, DEVICE)\n",
    "    \n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    train_psnrs.append(train_psnr_val)\n",
    "    val_psnrs.append(val_psnr_val)\n",
    "    train_ssims.append(train_ssim_val)\n",
    "    val_ssims.append(val_ssim_val)\n",
    "    eval_psnrs.append(eval_psnr)\n",
    "    eval_ssims.append(eval_ssim)\n",
    "    \n",
    "    print(f'Epoch {epoch+1}/{EPOCHS}:')\n",
    "    print(f'Train Loss: {train_loss:.6f}, Train PSNR: {train_psnr_val:.2f}, Train SSIM: {train_ssim_val:.4f}')\n",
    "    print(f'Val Loss: {val_loss:.6f}, Val PSNR: {val_psnr_val:.2f}, Val SSIM: {val_ssim_val:.4f}')\n",
    "    print(f'Evaluation Set - PSNR: {eval_psnr:.2f}, SSIM: {eval_ssim:.4f}')\n",
    "    \n",
    "    if eval_psnr > best_eval_psnr:\n",
    "        best_eval_psnr = eval_psnr\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'val_loss': val_loss,\n",
    "            'eval_psnr': eval_psnr,\n",
    "            'eval_ssim': eval_ssim,\n",
    "        }, f'{CHECKPOINT_DIR}/best_model.pth')\n",
    "    \n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'val_loss': val_loss,\n",
    "        'eval_psnr': eval_psnr,\n",
    "        'eval_ssim': eval_ssim,\n",
    "    }, f'{CHECKPOINT_DIR}/checkpoint_epoch_{epoch+1}.pth')\n",
    "                \n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "\n",
    "print('\\nTraining completed, evaluating final model on validation images...')\n",
    "final_eval_psnr, final_eval_ssim = evaluate_validation_images(model, DEVICE)\n",
    "print(f'Final Model on Evaluation Set - PSNR: {final_eval_psnr:.2f}, SSIM: {final_eval_ssim:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667ab700",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load and evaluate the best model\n",
    "import os\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import json\n",
    "from torchvision import transforms\n",
    "\n",
    "BEST_MODEL_PATH = os.path.join(CHECKPOINT_DIR, 'best_model.pth')\n",
    "\n",
    "if os.path.exists(BEST_MODEL_PATH):\n",
    "    print(f'Loading best model from {BEST_MODEL_PATH}')\n",
    "    \n",
    "    best_model = EnhancedUNet().to(DEVICE)\n",
    "    \n",
    "    #Load the best model checkpoint\n",
    "    checkpoint = torch.load(BEST_MODEL_PATH, map_location=DEVICE)\n",
    "    best_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    best_epoch = checkpoint['epoch']\n",
    "    best_eval_psnr = checkpoint.get('eval_psnr', 0)\n",
    "    best_eval_ssim = checkpoint.get('eval_ssim', 0)\n",
    "    \n",
    "    print(f'Best model from epoch {best_epoch+1} with evaluation PSNR: {best_eval_psnr:.2f}, SSIM: {best_eval_ssim:.4f}')\n",
    "    \n",
    "    best_model.eval()\n",
    "    \n",
    "    final_eval_psnr, final_eval_ssim = evaluate_validation_images(best_model, DEVICE)\n",
    "    print(f'Final evaluation - PSNR: {final_eval_psnr:.2f}, SSIM: {final_eval_ssim:.4f}')\n",
    "    \n",
    "    def save_example_results(model, device, num_samples=4):\n",
    "        noisy_dir = 'evaluation/noisy'\n",
    "        clean_dir = 'evaluation/clean'\n",
    "        results_dir = 'evaluation_results'\n",
    "        \n",
    "        if not os.path.exists(results_dir):\n",
    "            os.makedirs(results_dir)\n",
    "        \n",
    "        noisy_images = [f for f in os.listdir(noisy_dir) if f.endswith(('.png', '.PNG', '.jpg', '.jpeg'))][:num_samples]\n",
    "        transform = transforms.ToTensor()\n",
    "        results = []\n",
    "        \n",
    "        for img_name in noisy_images:\n",
    "            noisy_path = os.path.join(noisy_dir, img_name)\n",
    "            clean_path = os.path.join(clean_dir, img_name)\n",
    "            \n",
    "            if not os.path.exists(clean_path):\n",
    "                continue\n",
    "                \n",
    "            patches_noisy, positions, _, original_size, window = create_patches(noisy_path, output_dir=None)\n",
    "            patches_clean, _, _, _, _ = create_patches(clean_path, output_dir=None)\n",
    "\n",
    "            denoised_patches = []\n",
    "            with torch.no_grad():\n",
    "                for patch in patches_noisy:\n",
    "                    patch_tensor = transform(patch).unsqueeze(0).to(device)\n",
    "                    denoised_patch = model(patch_tensor)\n",
    "                    denoised_patch = transforms.ToPILImage()(denoised_patch.squeeze().cpu())\n",
    "                    denoised_patches.append(denoised_patch)\n",
    "            \n",
    "            noisy_full = reconstruct_image(patches_noisy, positions, original_size, window)\n",
    "            clean_full = reconstruct_image(patches_clean, positions, original_size, window)\n",
    "            denoised_full = reconstruct_image(denoised_patches, positions, original_size, window)\n",
    "            \n",
    "            base_name = os.path.splitext(img_name)[0]\n",
    "            noisy_save_path = os.path.join(results_dir, f'{base_name}_noisy.png')\n",
    "            clean_save_path = os.path.join(results_dir, f'{base_name}_clean.png')\n",
    "            denoised_save_path = os.path.join(results_dir, f'{base_name}_denoised.png')\n",
    "            \n",
    "            noisy_full.save(noisy_save_path)\n",
    "            clean_full.save(clean_save_path)\n",
    "            denoised_full.save(denoised_save_path)\n",
    "            \n",
    "            clean_tensor = transform(clean_full).unsqueeze(0).to(device)\n",
    "            denoised_tensor = transform(denoised_full).unsqueeze(0).to(device)\n",
    "            \n",
    "            img_psnr = psnr(denoised_tensor, clean_tensor)\n",
    "            img_ssim = ssim(denoised_tensor, clean_tensor)\n",
    "            \n",
    "            results.append({\n",
    "                'image_name': base_name,\n",
    "                'psnr': img_psnr.item(),\n",
    "                'ssim': img_ssim.item(),\n",
    "                'paths': {\n",
    "                    'noisy': noisy_save_path,\n",
    "                    'clean': clean_save_path,\n",
    "                    'denoised': denoised_save_path\n",
    "                }\n",
    "            })\n",
    "        \n",
    "        return results\n",
    "\n",
    "    print('\\nGenerating example results...')\n",
    "    example_results = save_example_results(best_model, DEVICE)\n",
    "    \n",
    "    def show_example_results(results):\n",
    "        num_samples = len(results)\n",
    "        fig, axes = plt.subplots(num_samples, 3, figsize=(15, 5*num_samples))\n",
    "        \n",
    "        if num_samples == 1:\n",
    "            axes = [axes]\n",
    "        \n",
    "        for i, result in enumerate(results):\n",
    "            noisy = Image.open(result['paths']['noisy'])\n",
    "            clean = Image.open(result['paths']['clean'])\n",
    "            denoised = Image.open(result['paths']['denoised'])\n",
    "            \n",
    "            axes[i, 0].imshow(noisy)\n",
    "            axes[i, 0].set_title('Noisy')\n",
    "            axes[i, 0].axis('off')\n",
    "            \n",
    "            axes[i, 1].imshow(denoised)\n",
    "            axes[i, 1].set_title(f'Denoised\\nPSNR: {result[\"psnr\"]:.2f}, SSIM: {result[\"ssim\"]:.4f}')\n",
    "            axes[i, 1].axis('off')\n",
    "            \n",
    "            axes[i, 2].imshow(clean)\n",
    "            axes[i, 2].set_title('Clean')\n",
    "            axes[i, 2].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('evaluation_results/comparison.png')\n",
    "        plt.show()\n",
    "\n",
    "    print('\\nShowing example results:')\n",
    "    show_example_results(example_results)\n",
    "    \n",
    "else:\n",
    "    print(f'Error: Best model not found at {BEST_MODEL_PATH}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
